{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff14649",
   "metadata": {},
   "source": [
    "# The Following 2 Blocks are scripts to synthesize english number datasets the first is an optimal script while the second is nonoptimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb20fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# # --- CONFIGURATION ---\n",
    "# OUTPUT_DIR = \"dataset\"\n",
    "# SAMPLES_PER_DIGIT = 200 # How many images per number to generate\n",
    "# IMG_SIZE = (64, 64)      # Canvas size (larger than target to allow rotation/cropping)\n",
    "# FONT_PATH = \"arial.ttf\"  # <--- COPY A FONT FILE HERE!\n",
    "# FONT_SIZE = 45\n",
    "\n",
    "# # Create folders 0-9\n",
    "# if not os.path.exists(OUTPUT_DIR):\n",
    "#     os.makedirs(OUTPUT_DIR)\n",
    "# for i in range(10):\n",
    "#     os.makedirs(os.path.join(OUTPUT_DIR, str(i)), exist_ok=True)\n",
    "\n",
    "# def apply_augmentations(img_pil):\n",
    "#     \"\"\"\n",
    "#     Takes a clean PIL image and ruins it to look like a scanned ID.\n",
    "#     \"\"\"\n",
    "#     # Convert to NumPy for OpenCV processing\n",
    "#     img = np.array(img_pil) \n",
    "    \n",
    "#     # 1. Random Rotation (-10 to 10 degrees)\n",
    "#     angle = random.uniform(-10, 10)\n",
    "#     h, w = img.shape\n",
    "#     M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "#     img = cv2.warpAffine(img, M, (w, h), borderValue=0) # Black border\n",
    "\n",
    "#     # 2. Gaussian Blur (Simulate out-of-focus camera)\n",
    "#     if random.random() > 0.5:\n",
    "#         k = random.choice([3, 5])\n",
    "#         img = cv2.GaussianBlur(img, (k, k), 0)\n",
    "\n",
    "#     # 3. Noise (Simulate sensor grain)\n",
    "#     noise = np.random.randint(0, 50, (h, w), dtype='uint8')\n",
    "#     # Add noise only to non-black areas mostly, or just add it overall\n",
    "#     img = cv2.add(img, noise)\n",
    "\n",
    "#     # 4. Erosion/Dilation (Simulate ink bleeding or thin print)\n",
    "#     if random.random() > 0.5:\n",
    "#         kernel = np.ones((2,2), np.uint8)\n",
    "#         if random.choice([True, False]):\n",
    "#             img = cv2.erode(img, kernel, iterations=1)\n",
    "#         else:\n",
    "#             img = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "#     return img\n",
    "\n",
    "# def generate_dataset():\n",
    "#     print(f\"Generating {SAMPLES_PER_DIGIT} images per digit...\")\n",
    "    \n",
    "#     try:\n",
    "#         font = ImageFont.truetype(FONT_PATH, FONT_SIZE)\n",
    "#     except IOError:\n",
    "#         print(\"ERROR: Font file not found! Please put 'arial.ttf' in this folder.\")\n",
    "#         return\n",
    "\n",
    "#     for digit in range(10):\n",
    "#         print(f\"Processing digit: {digit}\")\n",
    "#         for i in range(SAMPLES_PER_DIGIT):\n",
    "#             # 1. Create a blank black image\n",
    "#             img_pil = Image.new('L', IMG_SIZE, color=0)\n",
    "#             draw = ImageDraw.Draw(img_pil)\n",
    "            \n",
    "#             # 2. Draw the digit in white centered(ish)\n",
    "#             # We add random offset so the number isn't always perfectly in the middle\n",
    "#             text = str(digit)\n",
    "#             # Get text bounding box to center it\n",
    "#             bbox = draw.textbbox((0, 0), text, font=font)\n",
    "#             text_w = bbox[2] - bbox[0]\n",
    "#             text_h = bbox[3] - bbox[1]\n",
    "            \n",
    "#             x = (IMG_SIZE[0] - text_w) / 2 + random.randint(-5, 5)\n",
    "#             y = (IMG_SIZE[1] - text_h) / 2 + random.randint(-5, 5)\n",
    "            \n",
    "#             draw.text((x, y), text, font=font, fill=255)\n",
    "            \n",
    "#             # 3. Apply the \"Reality\" effects\n",
    "#             final_img = apply_augmentations(img_pil)\n",
    "            \n",
    "#             # 4. Save\n",
    "#             save_path = os.path.join(OUTPUT_DIR, str(digit), f\"{digit}_{i}.png\")\n",
    "#             cv2.imwrite(save_path, final_img)\n",
    "\n",
    "#     print(\"Done! You now have a dataset.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1ec27cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# # --- CONFIGURATION ---\n",
    "# OUTPUT_DIR = \"dataset_mixed\"\n",
    "# SAMPLES_PER_DIGIT = 400  # Total images per digit\n",
    "# IMG_SIZE = (64, 64)\n",
    "\n",
    "# # List your fonts here. Ensure these files are in the folder!\n",
    "# FONTS = [\"arial.ttf\", \"Sitka.ttc\"] \n",
    "# FONT_SIZE = 45\n",
    "\n",
    "# # Create output folders\n",
    "# if not os.path.exists(OUTPUT_DIR):\n",
    "#     os.makedirs(OUTPUT_DIR)\n",
    "# for i in range(10):\n",
    "#     os.makedirs(os.path.join(OUTPUT_DIR, str(i)), exist_ok=True)\n",
    "\n",
    "# def add_shadow(img):\n",
    "#     \"\"\"Simulates uneven lighting.\"\"\"\n",
    "#     h, w = img.shape\n",
    "#     top_left = random.uniform(0.5, 1.0)\n",
    "#     bot_right = random.uniform(0.5, 1.0)\n",
    "#     X, Y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "#     mask = top_left + (bot_right - top_left) * (X / w)\n",
    "#     img = img.astype('float32') * mask\n",
    "#     return img.astype('uint8')\n",
    "\n",
    "# def break_character(img):\n",
    "#     \"\"\"Simulates scratches and missing chunks.\"\"\"\n",
    "#     h, w = img.shape\n",
    "    \n",
    "#     # Random scratch line\n",
    "#     if random.random() > 0.5:\n",
    "#         num_scratches = random.randint(1, 3)\n",
    "#         for _ in range(num_scratches):\n",
    "#             x1, y1 = random.randint(0, w), random.randint(0, h)\n",
    "#             x2, y2 = random.randint(0, w), random.randint(0, h)\n",
    "#             cv2.line(img, (x1, y1), (x2, y2), 0, random.randint(1, 3))\n",
    "\n",
    "#     # Random noise chunks missing\n",
    "#     if random.random() > 0.5:\n",
    "#         noise = np.zeros((h, w), dtype='uint8')\n",
    "#         cv2.randn(noise, 0, 255)\n",
    "#         _, holes = cv2.threshold(noise, 200, 255, cv2.THRESH_BINARY)\n",
    "#         img = cv2.subtract(img, holes)\n",
    "        \n",
    "#     return img\n",
    "\n",
    "# def apply_defects(img_pil):\n",
    "#     img = np.array(img_pil)\n",
    "    \n",
    "#     # 1. Perspective Warp\n",
    "#     h, w = img.shape\n",
    "#     src_points = np.float32([[0,0], [w,0], [0,h], [w,h]])\n",
    "#     dst_points = np.float32([\n",
    "#         [random.randint(0, 5), random.randint(0, 5)],\n",
    "#         [w - random.randint(0, 5), random.randint(0, 5)],\n",
    "#         [random.randint(0, 5), h - random.randint(0, 5)],\n",
    "#         [w - random.randint(0, 5), h - random.randint(0, 5)]\n",
    "#     ])\n",
    "#     M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "#     img = cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "#     # 2. Break Character\n",
    "#     img = break_character(img)\n",
    "\n",
    "#     # 3. Blur\n",
    "#     if random.random() > 0.3:\n",
    "#         k = random.choice([3, 5])\n",
    "#         img = cv2.GaussianBlur(img, (k, k), 0)\n",
    "\n",
    "#     # 4. Shadow\n",
    "#     if random.random() > 0.4:\n",
    "#         img = add_shadow(img)\n",
    "\n",
    "#     # 5. Salt & Pepper Noise\n",
    "#     noise_prob = 0.02\n",
    "#     thres = 1 - noise_prob\n",
    "#     rdn = np.random.random(img.shape)\n",
    "#     img[rdn < noise_prob] = 0\n",
    "#     img[rdn > thres] = 255\n",
    "\n",
    "#     return img\n",
    "\n",
    "# def generate_dataset():\n",
    "#     print(f\"Generating {SAMPLES_PER_DIGIT} images per digit using fonts: {FONTS}\")\n",
    "    \n",
    "#     # Verify fonts exist\n",
    "#     loaded_fonts = []\n",
    "#     for f_name in FONTS:\n",
    "#         try:\n",
    "#             loaded_fonts.append(ImageFont.truetype(f_name, FONT_SIZE))\n",
    "#         except IOError:\n",
    "#             print(f\"WARNING: Could not load {f_name}. Skipping.\")\n",
    "    \n",
    "#     if not loaded_fonts:\n",
    "#         print(\"ERROR: No fonts found! Please copy .ttf files to this folder.\")\n",
    "#         return\n",
    "\n",
    "#     for digit in range(10):\n",
    "#         print(f\"Processing digit: {digit}\")\n",
    "#         for i in range(SAMPLES_PER_DIGIT):\n",
    "#             # 1. Randomly choose a font\n",
    "#             font = random.choice(loaded_fonts)\n",
    "            \n",
    "#             # 2. Draw Text\n",
    "#             img_pil = Image.new('L', IMG_SIZE, color=0)\n",
    "#             draw = ImageDraw.Draw(img_pil)\n",
    "            \n",
    "#             text = str(digit)\n",
    "#             bbox = draw.textbbox((0, 0), text, font=font)\n",
    "#             text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "#             x = (IMG_SIZE[0] - text_w) / 2 + random.randint(-8, 8)\n",
    "#             y = (IMG_SIZE[1] - text_h) / 2 + random.randint(-8, 8)\n",
    "            \n",
    "#             draw.text((x, y), text, font=font, fill=255)\n",
    "            \n",
    "#             # 3. Apply Defects\n",
    "#             final_img = apply_defects(img_pil)\n",
    "            \n",
    "#             # 4. Save\n",
    "#             save_path = os.path.join(OUTPUT_DIR, str(digit), f\"{digit}_{i}.png\")\n",
    "#             cv2.imwrite(save_path, final_img)\n",
    "\n",
    "#     print(f\"Done! Created {SAMPLES_PER_DIGIT * 10} images in '{OUTPUT_DIR}'\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6c180f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils  # If you are unable to install this library, ask the TA; we only need this in extract_hsv_histogram.\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "# Depending on library versions on your system, one of the following imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c32ccb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"./dataset_mixed\"\n",
    "\n",
    "target_img_size = (32, 32) # fix image size because classification algorithms THAT WE WILL USE HERE expect that\n",
    "# We are going to fix the random seed to make our experiments reproducible \n",
    "# since some algorithms use pseudorandom generators\n",
    "random_seed = 42  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3a33c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    You won't implement anything in this function. You just need to understand it \n",
    "    and understand its parameters (i.e win_size, cell_size, ... etc)\n",
    "    \"\"\"\n",
    "    img = cv2.resize(img, target_img_size)\n",
    "    win_size = (32, 32)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e45a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(feature_set='hog'):\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames = os.listdir(path_to_dataset)\n",
    "    total_processed = 0\n",
    "    for folder in img_filenames:    \n",
    "        total_images += len(img_filenames) * len(os.listdir(os.path.join(path_to_dataset, folder)))   # 10 folders * 400 images each = 4000\n",
    "\n",
    "    for i, fn in enumerate(img_filenames):\n",
    "        NumberInnerPath = os.path.join(path_to_dataset, str(i))\n",
    "        NumberInnerPath = os.listdir(NumberInnerPath)\n",
    "        for idx, img_filename in enumerate(NumberInnerPath):\n",
    "            if img_filename.split('.')[-1] != 'png':\n",
    "                continue\n",
    "\n",
    "            label = str(i)\n",
    "            labels.append(label)\n",
    "\n",
    "            # Build the full file path\n",
    "            full_path = os.path.join(path_to_dataset, str(i), img_filename)\n",
    "            img = cv2.imread(full_path)\n",
    "            features.append(extract_hog_features(img))\n",
    "            \n",
    "            total_processed += 1\n",
    "            \n",
    "            # show an update every 50 images\n",
    "            if total_processed > 0 and total_processed % 50 == 0:\n",
    "                print(\"[INFO] processed {}/{} images\".format(total_processed, total_images))\n",
    "        \n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5092b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM():\n",
    "    SVMclassifier=svm.LinearSVC(random_state=random_seed)\n",
    "    features, labels = load_dataset()\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.4, random_state=random_seed)\n",
    "    SVMclassifier.fit(train_features,train_labels)\n",
    "    accuracy=SVMclassifier.score(test_features,test_labels)\n",
    "    print(\"SVM Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf82cf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 50/2000 images\n",
      "[INFO] processed 100/2000 images\n",
      "[INFO] processed 150/2000 images\n",
      "[INFO] processed 200/2000 images\n",
      "[INFO] processed 250/2000 images\n",
      "[INFO] processed 300/2000 images\n",
      "[INFO] processed 350/2000 images\n",
      "[INFO] processed 400/2000 images\n",
      "[INFO] processed 450/2000 images\n",
      "[INFO] processed 500/2000 images\n",
      "[INFO] processed 550/2000 images\n",
      "[INFO] processed 600/2000 images\n",
      "[INFO] processed 650/2000 images\n",
      "[INFO] processed 700/2000 images\n",
      "[INFO] processed 750/2000 images\n",
      "[INFO] processed 800/2000 images\n",
      "[INFO] processed 850/2000 images\n",
      "[INFO] processed 900/2000 images\n",
      "[INFO] processed 950/2000 images\n",
      "[INFO] processed 1000/2000 images\n",
      "[INFO] processed 1050/2000 images\n",
      "[INFO] processed 1100/2000 images\n",
      "[INFO] processed 1150/2000 images\n",
      "[INFO] processed 1200/2000 images\n",
      "[INFO] processed 1250/2000 images\n",
      "[INFO] processed 1300/2000 images\n",
      "[INFO] processed 1350/2000 images\n",
      "[INFO] processed 1400/2000 images\n",
      "[INFO] processed 1450/2000 images\n",
      "[INFO] processed 1500/2000 images\n",
      "[INFO] processed 1550/2000 images\n",
      "[INFO] processed 1600/2000 images\n",
      "[INFO] processed 1650/2000 images\n",
      "[INFO] processed 1700/2000 images\n",
      "[INFO] processed 1750/2000 images\n",
      "[INFO] processed 1800/2000 images\n",
      "[INFO] processed 1850/2000 images\n",
      "[INFO] processed 1900/2000 images\n",
      "[INFO] processed 1950/2000 images\n",
      "[INFO] processed 2000/2000 images\n",
      "[INFO] processed 2050/2000 images\n",
      "[INFO] processed 2100/2000 images\n",
      "[INFO] processed 2150/2000 images\n",
      "[INFO] processed 2200/2000 images\n",
      "[INFO] processed 2250/2000 images\n",
      "[INFO] processed 2300/2000 images\n",
      "[INFO] processed 2350/2000 images\n",
      "[INFO] processed 2400/2000 images\n",
      "[INFO] processed 2450/2000 images\n",
      "[INFO] processed 2500/2000 images\n",
      "[INFO] processed 2550/2000 images\n",
      "[INFO] processed 2600/2000 images\n",
      "[INFO] processed 2650/2000 images\n",
      "[INFO] processed 2700/2000 images\n",
      "[INFO] processed 2750/2000 images\n",
      "[INFO] processed 2800/2000 images\n",
      "[INFO] processed 2850/2000 images\n",
      "[INFO] processed 2900/2000 images\n",
      "[INFO] processed 2950/2000 images\n",
      "[INFO] processed 3000/2000 images\n",
      "[INFO] processed 3050/2000 images\n",
      "[INFO] processed 3100/2000 images\n",
      "[INFO] processed 3150/2000 images\n",
      "[INFO] processed 3200/2000 images\n",
      "[INFO] processed 3250/2000 images\n",
      "[INFO] processed 3300/2000 images\n",
      "[INFO] processed 3350/2000 images\n",
      "[INFO] processed 3400/2000 images\n",
      "[INFO] processed 3450/2000 images\n",
      "[INFO] processed 3500/2000 images\n",
      "[INFO] processed 3550/2000 images\n",
      "[INFO] processed 3600/2000 images\n",
      "[INFO] processed 3650/2000 images\n",
      "[INFO] processed 3700/2000 images\n",
      "[INFO] processed 3750/2000 images\n",
      "[INFO] processed 3800/2000 images\n",
      "[INFO] processed 3850/2000 images\n",
      "[INFO] processed 3900/2000 images\n",
      "[INFO] processed 3950/2000 images\n",
      "[INFO] processed 4000/2000 images\n",
      "SVM Accuracy:  0.875625\n"
     ]
    }
   ],
   "source": [
    "train_SVM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
