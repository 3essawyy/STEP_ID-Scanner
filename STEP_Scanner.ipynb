{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23ba08ac",
   "metadata": {},
   "source": [
    "## **Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10cf11c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "#import imutils  # If you are unable to install this library, ask the TA; we only need this in extract_hsv_histogram.\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pytesseract\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from arabic_reshaper import reshape\n",
    "from bidi.algorithm import get_display\n",
    "import pandas as pd\n",
    "from openpyxl.utils import get_column_letter  # Add this line\n",
    "from commonfunctions import *\n",
    "import numpy as np\n",
    "import unittest\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe' # (Windows Example)\n",
    "\n",
    "\n",
    "target_img_size = (32, 32) # fix image size because classification algorithms THAT WE WILL USE HERE expect that\n",
    "# We are going to fix the random seed to make our experiments reproducible \n",
    "# since some algorithms use pseudorandom generators\n",
    "random_seed = 42  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f94a9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # === Single-ID preprocessing debug (set RAW_ID and run) ===\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from PIL import Image\n",
    "\n",
    "# RAW_ID = 7  # <- change this (e.g., 2, 14, 37...)\n",
    "# REFERENCE_ID = 14  # reference card used for alignment\n",
    "# EXT = '.jpg'\n",
    "# APPLY_GLARE_REMOVAL = True  # <- set False to skip\n",
    "# GLARE_V_THRESH = 235\n",
    "# GLARE_S_THRESH = 80\n",
    "# APPLY_PIL_UPSCALE = True  # <- set False to load with cv2.imread only\n",
    "\n",
    "\n",
    "# def enhance_image_quality(image_path):\n",
    "#     \"\"\"Enhance image quality to improve OCR accuracy.\"\"\"\n",
    "#     try:\n",
    "#         img = Image.open(image_path)\n",
    "#         # Increase resolution if image is small\n",
    "#         if max(img.size) < 800:\n",
    "#             new_size = (img.size[0] * 2, img.size[1] * 2)\n",
    "#             img = img.resize(new_size, Image.Resampling.LANCZOS)\n",
    "#         return img\n",
    "#     except Exception:\n",
    "#         return Image.open(image_path)\n",
    "\n",
    "\n",
    "# def load_image_bgr(image_path: str) -> np.ndarray:\n",
    "#     \"\"\"Load image as OpenCV BGR, optionally upscaling with PIL first.\"\"\"\n",
    "#     if APPLY_PIL_UPSCALE:\n",
    "#         try:\n",
    "#             pil_img = enhance_image_quality(image_path).convert('RGB')\n",
    "#             rgb = np.array(pil_img)\n",
    "#             return cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)\n",
    "#         except Exception:\n",
    "#             pass\n",
    "\n",
    "#     return cv2.imread(image_path)\n",
    "\n",
    "\n",
    "# def _show(img, title):\n",
    "#     if img is None:\n",
    "#         print(f\"{title}: <None>\")\n",
    "#         return\n",
    "#     plt.figure(figsize=(6, 4))\n",
    "#     if len(img.shape) == 2:\n",
    "#         plt.imshow(img, cmap='gray')\n",
    "#     else:\n",
    "#         plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "#     plt.title(title)\n",
    "#     plt.axis('off')\n",
    "#     plt.show()\n",
    "\n",
    "\n",
    "# base_dir = os.getcwd()\n",
    "# raw_path = os.path.join(base_dir, 'Raw_IDs', f'ID{RAW_ID}{EXT}')\n",
    "# ref_path = os.path.join(base_dir, 'Raw_IDs', f'ID{REFERENCE_ID}{EXT}')\n",
    "\n",
    "# if not os.path.exists(raw_path):\n",
    "#     raise FileNotFoundError(f\"Raw image not found: {raw_path}\")\n",
    "# if not os.path.exists(ref_path):\n",
    "#     raise FileNotFoundError(f\"Reference image not found: {ref_path}\")\n",
    "\n",
    "# raw_img = load_image_bgr(raw_path)\n",
    "# _show(raw_img, f\"Step 0 - Raw (ID{RAW_ID})\")\n",
    "\n",
    "# if APPLY_GLARE_REMOVAL:\n",
    "#     glare_fixed, glare_mask = remove_glare_spots(raw_img, v_thresh=GLARE_V_THRESH, s_thresh=GLARE_S_THRESH)\n",
    "#     _show(glare_mask, \"Step 0b - Glare mask\")\n",
    "#     _show(glare_fixed, \"Step 0c - After glare removal\")\n",
    "#     img0 = glare_fixed\n",
    "# else:\n",
    "#     img0 = raw_img\n",
    "\n",
    "# clean_img, is_impulsive = is_impulsive_noise(img0)\n",
    "# print('Impulsive noise detected:', is_impulsive)\n",
    "# _show(clean_img, \"Step 1 - After impulsive noise removal\")\n",
    "\n",
    "# aligned_img = align_images_sift(clean_img, ref_path)\n",
    "# _show(aligned_img, f\"Step 2 - After alignment to ID{REFERENCE_ID}\")\n",
    "\n",
    "# clean_img2, is_random = is_random_noise(aligned_img)\n",
    "# print('Random noise detected:', is_random)\n",
    "# _show(clean_img2, \"Step 3 - After random noise removal\")\n",
    "\n",
    "# enhanced_img = enhance_contrast_clahe(clean_img2)\n",
    "# _show(enhanced_img, \"Step 4 - After contrast enhancement\")\n",
    "\n",
    "# name_img, digit_imgs, daf3_digits = extract_name_and_digits(enhanced_img)\n",
    "# _show(name_img, \"Step 5a - Cropped name region\")\n",
    "\n",
    "# # Show code digits (first row)\n",
    "# if isinstance(digit_imgs, (list, tuple)) and len(digit_imgs) > 0:\n",
    "#     for idx, d in enumerate(digit_imgs):\n",
    "#         _show(d, f\"Step 5b - Code digit {idx}\")\n",
    "# else:\n",
    "#     print('No code digits returned from extract_name_and_digits')\n",
    "\n",
    "# # Show Daf3 digits\n",
    "# if isinstance(daf3_digits, (list, tuple)) and len(daf3_digits) > 0:\n",
    "#     for idx, d in enumerate(daf3_digits):\n",
    "#         _show(d, f\"Step 5c - Daf3 digit {idx}\")\n",
    "# else:\n",
    "#     print('No Daf3 digits returned from extract_name_and_digits')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967cc75f",
   "metadata": {},
   "source": [
    "## GPU setup (EasyOCR / Qwen / PaddleOCR)\n",
    "Run the next cell to check if CUDA is available in this environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61f26fdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS: Windows-11-10.0.26200-SP0\n",
      "Python: 3.12.6 (tags/v3.12.6:a4a2d2b, Sep  6 2024, 20:11:23) [MSC v.1940 64 bit (AMD64)]\n",
      "Executable: c:\\Program Files\\Python312\\python.exe\n",
      "numpy: 2.2.6\n",
      "torch: 2.9.1+cpu\n",
      "torch cuda_available: False\n",
      "paddle import failed: No module named 'paddle'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import sys\n",
    "\n",
    "print('OS:', platform.platform())\n",
    "print('Python:', sys.version)\n",
    "print('Executable:', sys.executable)\n",
    "\n",
    "# Workaround for a common Windows conda issue (harmless if not needed)\n",
    "# If you see: \"OMP: Error #15: Initializing libiomp5md.dll...\" then keep this.\n",
    "os.environ.setdefault('KMP_DUPLICATE_LIB_OK', 'TRUE')\n",
    "\n",
    "# ---- NumPy ----\n",
    "try:\n",
    "    import numpy as np\n",
    "    print('numpy:', np.__version__)\n",
    "except Exception as e:\n",
    "    print('numpy import failed:', e)\n",
    "\n",
    "# ---- PyTorch (EasyOCR + Qwen) ----\n",
    "try:\n",
    "    import torch\n",
    "    print('torch:', torch.__version__)\n",
    "    print('torch cuda_available:', torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print('torch cuda version:', torch.version.cuda)\n",
    "        print('torch device 0:', torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print('torch import failed:', e)\n",
    "\n",
    "# ---- PaddlePaddle (PaddleOCR) ----\n",
    "try:\n",
    "    import paddle\n",
    "    print('paddle:', paddle.__version__)\n",
    "    print('paddle cuda_compiled:', paddle.device.is_compiled_with_cuda())\n",
    "except Exception as e:\n",
    "    print('paddle import failed:', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e03b6e",
   "metadata": {},
   "source": [
    "### What to do to run on GPU (and fix EasyOCR import errors)\n",
    "1) Run the GPU check cell above.\n",
    "- If it prints `torch cuda_available: True` then EasyOCR + Qwen will use GPU.\n",
    "- If it prints `torch ... +cpu` or `torch cuda_available: False`, install CUDA PyTorch (recommended in conda):\n",
    "  - `conda install -y -n imageproc pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia`\n",
    "  - Restart the notebook kernel and re-run the GPU check.\n",
    "\n",
    "2) If you get this error when importing EasyOCR / torchvision:\n",
    "`ImportError: cannot import name 'DiagnosticOptions' from 'torch.onnx._internal.exporter'`\n",
    "That means your environment has **mismatched** `torch` and `torchvision` (usually because of pip installs on top of conda). Fix by removing pip torch packages and reinstalling the conda stack:\n",
    "- `python -m pip uninstall -y torch torchvision torchaudio`\n",
    "- `conda install -y -n imageproc pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch -c nvidia`\n",
    "- Restart the notebook kernel.\n",
    "\n",
    "3) PaddleOCR GPU note (optional)\n",
    "- Your current pipeline uses **EasyOCR** for names (not PaddleOCR), so Paddle CUDA is **not required** unless you switch back to PaddleOCR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f7a19f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 2.2.6\n",
      "torch: 2.9.1+cpu cuda_available: False\n",
      "torchvision: 0.24.1+cpu\n",
      "easyocr: 1.7.2\n"
     ]
    }
   ],
   "source": [
    "# Quick verification (run after you restart the kernel)\n",
    "import os\n",
    "os.environ.setdefault('KMP_DUPLICATE_LIB_OK', 'TRUE')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import easyocr\n",
    "\n",
    "print('numpy:', np.__version__)\n",
    "print('torch:', torch.__version__, 'cuda_available:', torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print('GPU:', torch.cuda.get_device_name(0))\n",
    "print('torchvision:', torchvision.__version__)\n",
    "print('easyocr:', easyocr.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8ab16d",
   "metadata": {},
   "source": [
    "## **Main Functions Overview**\n",
    "\n",
    "- **Image Alignment**\n",
    "  - Detects SIFT keypoints and descriptors in the input and reference images.\n",
    "  - Matches them using the ratio test.\n",
    "  - Uses RANSAC to estimate a homography.\n",
    "  - Applies the homography to warp the input image so it lines up with the reference.\n",
    "  - Returns the aligned image (or the original if not enough matches are found).\n",
    "\n",
    "- **Extract Details**\n",
    "  - Uses (x, y, w, h) coordinates to crop the aligned card into:\n",
    "    - The name region\n",
    "    - The code (ID) region\n",
    "  - Returns these sub-images for downstream OCR or digit processing.\n",
    "\n",
    "- **Save Student Name**\n",
    "  - Ensures the output folder exists.\n",
    "  - Writes the cropped name image to disk with a filename that includes the student ID.\n",
    "  - Creates a persistent record usable for manual review or OCR.\n",
    "\n",
    "- **Split and Save Digits**\n",
    "  - Converts the code region to grayscale and applies Otsu thresholding.\n",
    "  - Finds contours and filters out small noise.\n",
    "  - Selects the largest seven contours (by area) and sorts them left-to-right.\n",
    "  - Saves each detected digit crop into a per-student folder as individual image files.\n",
    "\n",
    "- **save_split_digits**\n",
    "  - Takes a list of digit images for a student.\n",
    "  - Ensures a folder exists for each student (named by their ID).\n",
    "  - Saves each digit image as `digit_0.jpg`, `digit_1.jpg`, ..., `digit_6.jpg` inside the student’s folder.\n",
    "  - Used for batch saving when all digit crops are already extracted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945bafe",
   "metadata": {},
   "source": [
    "## **Noise Detection and Treatment**\n",
    "- **Impulsive Noise (Median Filter)**\n",
    "- **Random Noise (Gaussian Filter)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f54ba87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_random_noise(img, threshold=0.1):\n",
    "    \"\"\"\n",
    "    Detects random noise and applies Non-Local Means (NLM) Denoising.\n",
    "    This is the best traditional filter for preserving textures and sharp edges.\n",
    "    \"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Estimate noise level\n",
    "    stddev = np.std(img)\n",
    "    normalized_stddev = stddev / 255.0\n",
    "\n",
    "    if normalized_stddev < threshold:\n",
    "        return img, False\n",
    "\n",
    "    # cv2.fastNlMeansDenoising(src, h, templateWindowSize, searchWindowSize)\n",
    "    # h: Parameter deciding filter strength. Higher = more noise removal but less detail. \n",
    "    #    (10 is usually a good starting point for moderate noise)\n",
    "    # templateWindowSize: Size of the patches used to compute weights (typically 7).\n",
    "    # searchWindowSize: Size of the window to search for similar patches (typically 21).\n",
    "    \n",
    "    treated_img = cv2.fastNlMeansDenoising(\n",
    "        img, \n",
    "        None, \n",
    "        h=10, \n",
    "        templateWindowSize=7, \n",
    "        searchWindowSize=21\n",
    "    )\n",
    "    \n",
    "    return treated_img, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53737cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def is_impulsive_noise(img, threshold=0.1, black_range=(0, 9), white_range=(246, 255)):\n",
    "    \"\"\"\n",
    "    Detects impulsive noise and applies a Decision-Based Median Filter.\n",
    "    Only noisy pixels are modified; clean pixels remain sharp and unblurred.\n",
    "    \"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "    total_pixels = img.size\n",
    "    # Create masks for pixels that fall into the 'salt' or 'pepper' ranges\n",
    "    is_pepper = (img >= black_range[0]) & (img <= black_range[1])\n",
    "    is_salt = (img >= white_range[0]) & (img <= white_range[1])\n",
    "    \n",
    "    # Combined noise mask\n",
    "    noise_mask = is_pepper | is_salt\n",
    "    num_noise_pixels = np.sum(noise_mask)\n",
    "    prop = num_noise_pixels / total_pixels\n",
    "\n",
    "    if prop < threshold:\n",
    "        return img, False \n",
    "\n",
    "    # Determine kernel size based on noise severity\n",
    "    k = int(3 + prop * 10)\n",
    "    if k % 2 == 0: k += 1\n",
    "    k = min(max(k, 3), 9)\n",
    "\n",
    "    # 1. Apply a standard median blur to a temporary image\n",
    "    median_filtered = cv2.medianBlur(img, k)\n",
    "\n",
    "    # 2. DECISION STEP: Create output as a copy of the original\n",
    "    # This ensures we don't blur the whole image.\n",
    "    treated_img = img.copy()\n",
    "\n",
    "    # 3. Only replace pixels where the noise_mask is True\n",
    "    treated_img[noise_mask] = median_filtered[noise_mask]\n",
    "\n",
    "    return treated_img, True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dba8fd2",
   "metadata": {},
   "source": [
    "Contrast enhancment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0082918a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def enhance_contrast_clahe(img, clip_limit=2.0, tile_size=(8, 8)):\n",
    "    \"\"\"\n",
    "    Applies CLAHE for high-quality contrast enhancement.\n",
    "    Returns the enhanced image.\n",
    "    \"\"\"\n",
    "    if len(img.shape) == 3:\n",
    "        # Convert to LAB to enhance only the Luminance (L) channel\n",
    "        # This prevents color distortion.\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        \n",
    "        # Create CLAHE object\n",
    "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)\n",
    "        cl = clahe.apply(l)\n",
    "        \n",
    "        # Merge back and convert to BGR\n",
    "        enhanced_lab = cv2.merge((cl, a, b))\n",
    "        return cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
    "    else:\n",
    "        # Grayscale implementation\n",
    "        clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_size)\n",
    "        return clahe.apply(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dccdf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def boost_black_text(img):\n",
    "    # Handle both color and grayscale images\n",
    "    if len(img.shape) == 2:\n",
    "        # Grayscale input: apply CLAHE directly\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))\n",
    "        return clahe.apply(img)\n",
    "    else:\n",
    "        # Color input: convert to LAB, enhance L channel, convert back\n",
    "        lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "        l, a, b = cv2.split(lab)\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8,8))\n",
    "        l = clahe.apply(l)\n",
    "        lab = cv2.merge((l,a,b))\n",
    "        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f88c1d",
   "metadata": {},
   "source": [
    "## Flashlight Spot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0d06e2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def remove_glare_spots(\n",
    "    img,\n",
    "    v_thresh=225,\n",
    "    s_thresh=85,        \n",
    "    dilate_iter=2,\n",
    "    inpaint_radius=4\n",
    "):\n",
    "    if img is None:\n",
    "        return None, None\n",
    "\n",
    "    orig_dtype = img.dtype\n",
    "\n",
    "    # --- Ensure uint8 ---\n",
    "    img_u8 = img\n",
    "    if img_u8.dtype != np.uint8:\n",
    "        img_f = img_u8.astype(np.float32)\n",
    "        if img_f.size and float(np.nanmax(img_f)) <= 1.0:\n",
    "            img_u8 = np.clip(img_f * 255.0, 0, 255).astype(np.uint8)\n",
    "        else:\n",
    "            img_u8 = np.clip(img_f, 0, 255).astype(np.uint8)\n",
    "\n",
    "    was_gray = (img_u8.ndim == 2)\n",
    "    if was_gray:\n",
    "        bgr = cv2.cvtColor(img_u8, cv2.COLOR_GRAY2BGR)\n",
    "    else:\n",
    "        if img_u8.shape[2] == 4:\n",
    "            bgr = cv2.cvtColor(img_u8, cv2.COLOR_BGRA2BGR)\n",
    "        else:\n",
    "            bgr = img_u8\n",
    "\n",
    "    # --- Glare detection ---\n",
    "    hsv = cv2.cvtColor(bgr, cv2.COLOR_BGR2HSV)\n",
    "    s = hsv[:, :, 1]\n",
    "    v = hsv[:, :, 2]\n",
    "\n",
    "    mask = ((v >= v_thresh) & (v >= 180) & (s <= s_thresh)).astype(np.uint8) * 255\n",
    "\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=1)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "\n",
    "    if dilate_iter > 0:\n",
    "        mask = cv2.dilate(mask, kernel, iterations=dilate_iter)\n",
    "\n",
    "    # --- PROTECT DARK DIGITS ---\n",
    "    gray = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
    "    DIGIT_BLACK_THRESH = 140\n",
    "    mask[gray < DIGIT_BLACK_THRESH] = 0\n",
    "\n",
    "    # Shrink mask so neighbors stay untouched\n",
    "    shrink_kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    safe_mask = cv2.erode(mask, shrink_kernel, iterations=1)\n",
    "\n",
    "    if safe_mask.max() == 0:\n",
    "        return img.copy(), safe_mask\n",
    "\n",
    "    # --- Inpainting ---\n",
    "    inpainted = cv2.inpaint(bgr, safe_mask, inpaint_radius, cv2.INPAINT_TELEA)\n",
    "\n",
    "    # Soft blend\n",
    "    alpha = cv2.GaussianBlur(safe_mask.astype(np.float32) / 255.0, (0, 0), 2.0)\n",
    "    alpha3 = alpha[:, :, None]\n",
    "    blended = (bgr.astype(np.float32) * (1 - alpha3) +\n",
    "               inpainted.astype(np.float32) * alpha3)\n",
    "    blended = np.clip(blended, 0, 255).astype(np.uint8)\n",
    "\n",
    "    out_u8 = cv2.cvtColor(blended, cv2.COLOR_BGR2GRAY) if was_gray else blended\n",
    "\n",
    "    # --- Restore dtype ---\n",
    "    if orig_dtype == np.uint8:\n",
    "        out = out_u8\n",
    "    elif np.issubdtype(orig_dtype, np.floating):\n",
    "        if float(np.nanmax(img)) <= 1.0:\n",
    "            out = (out_u8.astype(np.float32) / 255.0).astype(orig_dtype)\n",
    "        else:\n",
    "            out = out_u8.astype(orig_dtype)\n",
    "    else:\n",
    "        out = out_u8.astype(orig_dtype)\n",
    "\n",
    "    return out, safe_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cf03c830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_images_sift(img_to_align, reference_path):\n",
    "    img1 = img_to_align\n",
    "    img2 = cv2.imread(reference_path)      # Train Image (The perfect template)\n",
    "    \n",
    "    # --- FIX: Check if img1 is already grayscale ---\n",
    "    if len(img1.shape) == 3:\n",
    "        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray1 = img1 # Already grayscale\n",
    "\n",
    "    # Ref image is loaded from disk, usually BGR, but good to check\n",
    "    if len(img2.shape) == 3:\n",
    "        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        gray2 = img2\n",
    "\n",
    "    sift = cv2.SIFT_create() \n",
    "    \n",
    "    kp1, des1 = sift.detectAndCompute(gray1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(gray2, None)\n",
    "\n",
    "    bf = cv2.BFMatcher()\n",
    "    matches = bf.knnMatch(des1, des2, k=2)\n",
    "\n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.75 * n.distance:\n",
    "            good_matches.append(m)\n",
    "\n",
    "    if len(good_matches) > 10:\n",
    "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
    "\n",
    "        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n",
    "\n",
    "        h, w = img2.shape[:2]\n",
    "        # Warp the original img1 (whether gray or color)\n",
    "        aligned_img = cv2.warpPerspective(img1, M, (w, h))\n",
    "\n",
    "        return aligned_img\n",
    "    \n",
    "    else:\n",
    "        print(f\"Not enough matches found: {len(good_matches)}/10\")\n",
    "        return img1\n",
    "    \n",
    "\n",
    "\n",
    "def extract_details(aligned_image):\n",
    "    name_coords = (100, 205, 1200, 150)\n",
    "    code_coords = (640, 404, 335, 110)\n",
    "    \n",
    "    nx, ny, nw, nh = name_coords\n",
    "    cx, cy, cw, ch = code_coords\n",
    "    \n",
    "    name_contour = aligned_image[ny:ny+nh, nx:nx+nw]\n",
    "    code_contour = aligned_image[cy:cy+ch, cx:cx+cw]\n",
    "    \n",
    "    return name_contour, code_contour\n",
    "\n",
    "\n",
    "def save_student_name(student_id, name_img, output_folder=\"extracted_names\"):\n",
    "    # Create folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "        \n",
    "    # Construct filename: extracted_names/ID1_name.jpg\n",
    "    filename = f\"{output_folder}/{student_id}_name.jpg\"\n",
    "    \n",
    "    # Save the image\n",
    "    cv2.imwrite(filename, name_img)\n",
    "    \n",
    "\n",
    "def split_and_save_digits(student_id, code_roi, output_folder=\"extracted_digits\"):\n",
    "    save_path = f\"{output_folder}/ID{student_id}\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "        \n",
    "    gray = cv2.cvtColor(code_roi, cv2.COLOR_BGR2GRAY)\n",
    "    _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # A. Collect all valid candidates\n",
    "    candidates = []\n",
    "    for cnt in contours:\n",
    "        x, y, w, h = cv2.boundingRect(cnt)\n",
    "        area = w * h\n",
    "        # Filter tiny noise\n",
    "        if h > 15 and w > 5:\n",
    "            candidates.append((x, y, w, h, area))\n",
    "            \n",
    "    # B. CRITICAL: Select exactly the top 7 by AREA (Size)\n",
    "    # This removes small specks or the colon \":\" if it was caught\n",
    "    candidates = sorted(candidates, key=lambda c: c[4], reverse=True) # Sort largest first\n",
    "    final_digits = candidates[:7] # Take top 7\n",
    "    \n",
    "    # C. Sort the final 7 by X-COORDINATE (Left -> Right)\n",
    "    # This puts them back in the correct reading order (1, 2, 3...)\n",
    "    final_digits = sorted(final_digits, key=lambda c: c[0])\n",
    "        \n",
    "    # D. Save\n",
    "    for index, (x, y, w, h, area) in enumerate(final_digits):\n",
    "        digit_img = code_roi[y:y+h, x:x+w]\n",
    "        filename = f\"{save_path}/digit_{index}.jpg\"\n",
    "        cv2.imwrite(filename, digit_img)\n",
    "\n",
    "      \n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def extract_name_and_digits(aligned_image):\n",
    "    \"\"\"\n",
    "    Input: An aligned ID card image.\n",
    "    Output: \n",
    "      - name_roi: The image of the extracted name.\n",
    "      - code_digits: A list of images for the code digits.\n",
    "      - daf3_digits: A list of images for the daf3 digits.\n",
    "    \"\"\"\n",
    "    \n",
    "    # --- 1. Hardcoded Coordinates ---\n",
    "    # x, y, w, h\n",
    "    name_coords = (100, 205, 1200, 150)\n",
    "    code_coords = (640, 404, 335, 110)\n",
    "    daf3_coords = (350, 500, 620, 110)\n",
    "    \n",
    "    nx, ny, nw, nh = name_coords\n",
    "    cx, cy, cw, ch = code_coords\n",
    "    dx, dy, dw, dh = daf3_coords\n",
    "    \n",
    "    # Extract ROIs\n",
    "    name_img = aligned_image[ny:ny+nh, nx:nx+nw]\n",
    "    code_roi = aligned_image[cy:cy+ch, cx:cx+cw]\n",
    "    daf3_img = aligned_image[dy:dy+dh, dx:dx+dw]\n",
    "    \n",
    "    # --- Helper Function to Process Any ROI ---\n",
    "    def process_roi_digits(roi_img, digit_limit):\n",
    "        \"\"\"\n",
    "        Applies grayscale, thresholding, contour detection, \n",
    "        splitting of merged digits, and sorting.\n",
    "        \"\"\"\n",
    "        #gray = cv2.cvtColor(roi_img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        if len(roi_img.shape) == 3:\n",
    "            gray = cv2.cvtColor(roi_img, cv2.COLOR_BGR2GRAY)\n",
    "        else:\n",
    "            gray = roi_img\n",
    "        # --- FIX ENDS HERE --\n",
    "        \n",
    "        # Binary Inverse + Otsu\n",
    "        _, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "        \n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        candidates = []\n",
    "        for cnt in contours:\n",
    "            x, y, w, h = cv2.boundingRect(cnt)\n",
    "            area = w * h\n",
    "            \n",
    "            # Filter tiny noise \n",
    "            if h > 15 and w > 5:\n",
    "                \n",
    "                # --- CHECK FOR MERGED DIGITS ---\n",
    "                # If width > 0.8 * height, likely two digits stuck together\n",
    "                if w > 0.8 * h: \n",
    "                    half_w = w // 2\n",
    "                    # Digit 1 (Left half)\n",
    "                    candidates.append((x, y, half_w, h, half_w * h))\n",
    "                    # Digit 2 (Right half)\n",
    "                    candidates.append((x + half_w, y, half_w, h, half_w * h))\n",
    "                else:\n",
    "                    # Normal single digit\n",
    "                    candidates.append((x, y, w, h, area))\n",
    "        \n",
    "        # 1. Sort by Area Descending (Keep only the largest objects to remove noise)\n",
    "        candidates = sorted(candidates, key=lambda c: c[4], reverse=True)[:digit_limit]\n",
    "        \n",
    "        # 2. Sort by X-coordinate Ascending (Order them Left -> Right)\n",
    "        final_candidates = sorted(candidates, key=lambda c: c[0])\n",
    "        \n",
    "        # Crop the actual images\n",
    "        cropped_digits = []\n",
    "        for (x, y, w, h, area) in final_candidates:\n",
    "            digit_crop = roi_img[y:y+h, x:x+w]\n",
    "            cropped_digits.append(digit_crop)\n",
    "            \n",
    "        return cropped_digits\n",
    "\n",
    "    # --- 2. Process Regions ---\n",
    "    \n",
    "    # Detect Code (Limit 7 digits)\n",
    "    code_digits = process_roi_digits(code_roi, digit_limit=7)\n",
    "    \n",
    "    # Detect Daf3 (Limit 14 digits)\n",
    "    daf3_digits = process_roi_digits(daf3_img, digit_limit=14)\n",
    "\n",
    "    return name_img, code_digits, daf3_digits\n",
    "\n",
    "def save_split_digits(student_id, digit_imgs, output_folder=\"extracted_digits\"):\n",
    "    \"\"\"\n",
    "    Saves a list of digit images for a student in the same way as split_and_save_digits.\n",
    "    Each digit is saved as digit_0.jpg, digit_1.jpg, ..., digit_6.jpg in a folder per student.\n",
    "    \"\"\"\n",
    "    save_path = f\"{output_folder}/{student_id}\"\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for index, digit_img in enumerate(digit_imgs):\n",
    "        filename = f\"{save_path}/digit_{index}.jpg\"\n",
    "        cv2.imwrite(filename, digit_img)    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f17014",
   "metadata": {},
   "source": [
    "## **SVM English Number Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0ff7086b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_dataset = r\"train_digits\"  # Training set\n",
    "\n",
    "def train_SVM_robust():\n",
    "    # 1. Map your specific filename prefixes to actual digits\n",
    "    label_map = {\n",
    "        'a': '0', 'b': '1', 'c': '2', 'd': '3', 'e': '4', \n",
    "        'f': '5', 'g': '6', 'h': '7', 'i': '8', 'j': '9'\n",
    "    }\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    img_filenames = os.listdir(path_to_train_dataset)\n",
    "    print(f\"Loading {len(img_filenames)} training images...\")\n",
    "\n",
    "    for fn in img_filenames:\n",
    "        if not fn.lower().endswith(('.jpg', '.png')):\n",
    "            continue\n",
    "\n",
    "        # Get the first letter (a, b, c...)\n",
    "        prefix = fn[0].lower()\n",
    "        if prefix in label_map:\n",
    "            labels.append(label_map[prefix])\n",
    "            \n",
    "            path = os.path.join(path_to_train_dataset, fn)\n",
    "            img = cv2.imread(path)\n",
    "            \n",
    "            # Extract HOG features (ensure preprocessing matches)\n",
    "            features.append(extract_hog_features(img))\n",
    "    \n",
    "    # 2. Create a Pipeline: Scale Features -> Train SVM\n",
    "    # Scaling is CRITICAL for HOG-based SVMs\n",
    "    clf = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('svc', LinearSVC(random_state=42, max_iter=5000, dual=False))\n",
    "    ])\n",
    "    \n",
    "    # 3. Train/Test Split for internal validation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        features, labels, test_size=0.2, random_state=random_seed\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    accuracy = clf.score(X_test, y_test)\n",
    "    print(f\"Training Complete. Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "    \n",
    "    return clf\n",
    "\n",
    "def extract_hog_features(img):\n",
    "    # Ensure grayscale\n",
    "    if len(img.shape) == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # APPLY IDENTICAL PREPROCESSING TO TRAINING AND TEST DATA\n",
    "    # This turns both sets into \"binary masks\" to ignore lighting/shadows\n",
    "    _, img = cv2.threshold(img, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "    \n",
    "    img = cv2.resize(img, (32, 32)) # target_img_size\n",
    "    \n",
    "    win_size = (32, 32)\n",
    "    cell_size = (8, 8)  # Slightly larger cells help ignore \"noise/shadows\"\n",
    "    block_size = (16, 16)\n",
    "    block_stride = (8, 8)\n",
    "    nbins = 9\n",
    "    \n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fbfe0",
   "metadata": {},
   "source": [
    "# **Tesseract Arabic OCR**\n",
    "\n",
    "## **Current Situation**\n",
    "\n",
    "The project uses Tesseract OCR to extract Arabic names from scanned images. Initially, the extraction pipeline achieved only a **70% success rate**. This meant that about 30% of the images failed to yield any valid Arabic text, even though the images were visually clear and contained readable names.\n",
    "\n",
    "## **Why Was the Success Rate Only 70%?**\n",
    "\n",
    "- **Overprocessing:** The original code applied several preprocessing steps (scaling, thresholding, blurring, etc.) before running OCR. While these steps can help with noisy or low-contrast images, they often **destroy clean, high-contrast text**—especially for Arabic, where fine details matter.\n",
    "- **Order of Operations:** The pipeline tried processed versions first, so if the original image was already optimal, it was never used for OCR.\n",
    "- **PSM/OEM Settings:** The code tried a limited set of Tesseract Page Segmentation Modes (PSM) and OCR Engine Modes (OEM), which may not have been optimal for all images.\n",
    "- **Text Cleaning:** The cleaning function was aggressive, but if Tesseract output was empty or too short, the result was discarded.\n",
    "\n",
    "## **What Was Changed to Achieve 100% Success**\n",
    "\n",
    "1. **Prioritize the Original Image:**  \n",
    "   The new code always tries the original, unprocessed grayscale image first, with several PSM settings. This ensures that clean images are not degraded by unnecessary processing.\n",
    "\n",
    "2. **Expanded Preprocessing (But Only If Needed):**  \n",
    "   Only if the original image fails, the code tries padded and scaled versions, but never applies destructive thresholding or blurring unless absolutely necessary.\n",
    "\n",
    "3. **Multiple PSM and OEM Combinations:**  \n",
    "   For each image variant, the code tries several PSM (6, 7, 3, 13) and both OEM (3, 1) settings, maximizing the chance that Tesseract will interpret the layout correctly.\n",
    "\n",
    "4. **Result Selection:**  \n",
    "   All non-empty results are collected, and the **longest valid extraction** is chosen, which is usually the correct full name.\n",
    "\n",
    "5. **Diagnostics:**  \n",
    "   Additional debug and diagnostic code was used to confirm that the original image, with minimal processing, consistently yields the best results for this dataset.\n",
    "\n",
    "# Reference\n",
    "\n",
    "The old (70%) code is left in the notebook for comparison. The new approach, as described above, achieves **100% extraction success** on the current dataset by respecting the quality of the input images and leveraging Tesseract's flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e532a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    }
   ],
   "source": [
    "# def extractname(img_path):\n",
    "    \n",
    "#     # --- HELPER: TEXT CLEANER ---\n",
    "#     def clean_text(raw_text):\n",
    "#         if not raw_text: return \"\"\n",
    "#         # Keep Arabic letters (0621-064A) and spaces\n",
    "#         cleaned = re.sub(r'[^\\u0621-\\u064A\\s]', '', raw_text)\n",
    "#         cleaned = cleaned.replace('\\n', ' ')\n",
    "#         cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "#         return cleaned\n",
    "\n",
    "#     # --- LOAD IMAGE AS GRAYSCALE DIRECTLY ---\n",
    "#     img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     if img_gray is None: \n",
    "#         return \"\"\n",
    "\n",
    "#     # Try multiple approaches and collect all results\n",
    "#     all_results = []\n",
    "    \n",
    "#     # Preprocessing variants\n",
    "#     preprocessed_images = {\n",
    "#         'original': img_gray,\n",
    "#         'padded': cv2.copyMakeBorder(img_gray, 40, 40, 40, 40, cv2.BORDER_CONSTANT, value=255),\n",
    "#     }\n",
    "    \n",
    "#     # Add scaled version\n",
    "#     h, w = img_gray.shape\n",
    "#     scaled = cv2.resize(img_gray, (w*2, h*2), interpolation=cv2.INTER_CUBIC)\n",
    "#     preprocessed_images['scaled_padded'] = cv2.copyMakeBorder(scaled, 40, 40, 40, 40, cv2.BORDER_CONSTANT, value=255)\n",
    "    \n",
    "#     # PSM modes to try\n",
    "#     psm_modes = [6, 7, 3, 13]  # 13 = raw line\n",
    "    \n",
    "#     for img_name, img in preprocessed_images.items():\n",
    "#         for psm in psm_modes:\n",
    "#             for oem in [3, 1]:  # Try both LSTM+Legacy and LSTM only\n",
    "#                 try:\n",
    "#                     config = f\"--oem {oem} --psm {psm}\"\n",
    "#                     text = pytesseract.image_to_string(img, lang='ara', config=config)\n",
    "#                     cleaned = clean_text(text)\n",
    "                    \n",
    "#                     if len(cleaned) > 2:\n",
    "#                         all_results.append((cleaned, len(cleaned), img_name, psm, oem))\n",
    "#                 except:\n",
    "#                     continue\n",
    "    \n",
    "#     # Return the longest valid result\n",
    "#     if all_results:\n",
    "#         all_results.sort(key=lambda x: x[1], reverse=True)\n",
    "#         return all_results[0][0]\n",
    "    \n",
    "#     return \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############################    easyOCR       #####################################\n",
    "\n",
    "\n",
    "\n",
    "import easyocr\n",
    "reader = easyocr.Reader(['ar', 'en'], gpu=True)\n",
    "\n",
    "def extractname(image_path):\n",
    "    \"\"\"\n",
    "    Reads text from the image path using EasyOCR.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        results = reader.readtext(image_path, detail=0, paragraph=True)\n",
    "        \n",
    "        # Join all detected text parts into one string\n",
    "        full_name = \" \".join(results)\n",
    "        return full_name.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"EasyOCR Error on {image_path}: {e}\")\n",
    "        return \"\"\n",
    "    \n",
    "\n",
    "#############################           PaddleOCR            ############################\n",
    "\n",
    "# import os\n",
    "\n",
    "# # Avoid slow \"model hoster connectivity\" checks on startup\n",
    "# os.environ.setdefault(\"DISABLE_MODEL_SOURCE_CHECK\", \"True\")\n",
    "\n",
    "# from paddleocr import PaddleOCR\n",
    "\n",
    "# # PaddleOCR v3.x: `use_gpu` and `use_angle_cls` are not valid args.\n",
    "# # For orientation/angle handling, use `use_textline_orientation`.\n",
    "# # Bump text-det resolution and relax thresholds so small words aren't missed.\n",
    "# ocr = PaddleOCR(\n",
    "#     lang='ar',\n",
    "#     use_textline_orientation=True,\n",
    "#     text_det_limit_side_len=1280,\n",
    "#     text_det_limit_type='max',\n",
    "#     text_det_thresh=0.2,\n",
    "#     text_det_box_thresh=0.3,\n",
    "#     text_det_unclip_ratio=1.8,\n",
    "# )\n",
    "\n",
    "\n",
    "# def _poly_center(poly):\n",
    "#     # poly is expected to be (4,2) array-like\n",
    "#     try:\n",
    "#         xs = [float(p[0]) for p in poly]\n",
    "#         ys = [float(p[1]) for p in poly]\n",
    "#         return (sum(xs) / len(xs), sum(ys) / len(ys))\n",
    "#     except Exception:\n",
    "#         return (0.0, 0.0)\n",
    "\n",
    "\n",
    "# def _group_into_lines(items, y_tol=18.0):\n",
    "#     \"\"\"Group (cx, cy, text) into lines by y coordinate.\"\"\"\n",
    "#     items = sorted(items, key=lambda t: t[1])\n",
    "#     lines = []\n",
    "#     current = []\n",
    "#     current_y = None\n",
    "\n",
    "#     for cx, cy, text in items:\n",
    "#         if current_y is None:\n",
    "#             current_y = cy\n",
    "#             current = [(cx, cy, text)]\n",
    "#             continue\n",
    "\n",
    "#         if abs(cy - current_y) <= y_tol:\n",
    "#             current.append((cx, cy, text))\n",
    "#             current_y = (current_y * (len(current) - 1) + cy) / len(current)\n",
    "#         else:\n",
    "#             lines.append(current)\n",
    "#             current = [(cx, cy, text)]\n",
    "#             current_y = cy\n",
    "\n",
    "#     if current:\n",
    "#         lines.append(current)\n",
    "\n",
    "#     return lines\n",
    "\n",
    "\n",
    "# def extractname(image_or_path):\n",
    "#     \"\"\"Reads Arabic name text from a path or ndarray using PaddleOCR.\"\"\"\n",
    "#     try:\n",
    "#         src = image_or_path\n",
    "#         if isinstance(src, str):\n",
    "#             img = cv2.imread(src)\n",
    "#         else:\n",
    "#             img = src\n",
    "#         if img is None:\n",
    "#             return \"\"\n",
    "\n",
    "#         # Pad the crop a bit to avoid clipping the first/last word at the borders.\n",
    "#         img = cv2.copyMakeBorder(img, 10, 10, 70, 70, cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
    "\n",
    "#         result = ocr.ocr(img)\n",
    "\n",
    "#         tokens = []\n",
    "\n",
    "#         # PaddleOCR v3.x output shape: list[dict], with keys like `rec_texts`, `rec_polys`.\n",
    "#         if isinstance(result, list) and result and isinstance(result[0], dict):\n",
    "#             for page in result:\n",
    "#                 rec_texts = page.get('rec_texts') or []\n",
    "#                 rec_polys = page.get('rec_polys') or []\n",
    "\n",
    "#                 if isinstance(rec_texts, list) and isinstance(rec_polys, list) and len(rec_texts) == len(rec_polys):\n",
    "#                     items = []\n",
    "#                     for t, poly in zip(rec_texts, rec_polys):\n",
    "#                         if not isinstance(t, str):\n",
    "#                             continue\n",
    "#                         t = t.strip()\n",
    "#                         if not t:\n",
    "#                             continue\n",
    "#                         cx, cy = _poly_center(poly)\n",
    "#                         items.append((cx, cy, t))\n",
    "\n",
    "#                     # Group into lines by Y, then sort each line RTL (X desc)\n",
    "#                     for line in _group_into_lines(items):\n",
    "#                         line_sorted = sorted(line, key=lambda t: t[0], reverse=True)\n",
    "#                         tokens.extend([t for _, __, t in line_sorted])\n",
    "#                 else:\n",
    "#                     # Fallback: just take the text list order as-is\n",
    "#                     if isinstance(rec_texts, list):\n",
    "#                         tokens.extend([t.strip() for t in rec_texts if isinstance(t, str) and t.strip()])\n",
    "#                     elif isinstance(rec_texts, str) and rec_texts.strip():\n",
    "#                         tokens.append(rec_texts.strip())\n",
    "\n",
    "#         else:\n",
    "#             # Older output shape: [[ [box, (text, score)], ... ]]\n",
    "#             try:\n",
    "#                 for line in result:\n",
    "#                     for res in line:\n",
    "#                         t = res[1][0]\n",
    "#                         if isinstance(t, str) and t.strip():\n",
    "#                             tokens.append(t.strip())\n",
    "#             except Exception:\n",
    "#                 pass\n",
    "\n",
    "#         # Clean: keep Arabic letters and spaces\n",
    "#         if tokens:\n",
    "#             joined = \" \".join(tokens)\n",
    "#             joined = re.sub(r'[^\\u0621-\\u064A\\s]', '', joined)\n",
    "#             joined = re.sub(r'\\s+', ' ', joined).strip()\n",
    "#             return joined\n",
    "\n",
    "#         return \"\"\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"PaddleOCR Error on {type(image_or_path).__name__}: {e}\")\n",
    "#         return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1acdaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pipeline_accuracy(true_file_path, extracted_file_path):\n",
    "    # 1. Load the Excel files\n",
    "    try:\n",
    "        # Load files (Sheet 1 is default, which is what we want now)\n",
    "        df_true = pd.read_excel(true_file_path)\n",
    "        df_extracted = pd.read_excel(extracted_file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading files: {e}\")\n",
    "        return 0.0\n",
    "\n",
    "    # --- CRITICAL FIX: Clean Column Names ---\n",
    "    # This removes leading/trailing spaces from headers (e.g., ' Name' -> 'Name')\n",
    "    df_true.columns = df_true.columns.str.strip()\n",
    "    df_extracted.columns = df_extracted.columns.str.strip()\n",
    "\n",
    "    # 2. Align the data lengths\n",
    "    min_len = min(len(df_true), len(df_extracted))\n",
    "    df_true = df_true.iloc[:min_len].reset_index(drop=True)\n",
    "    df_extracted = df_extracted.iloc[:min_len].reset_index(drop=True)\n",
    "\n",
    "    # Use the clean names now\n",
    "    columns_to_check = ['Code', 'Daf3', 'Name']\n",
    "    scores = {}\n",
    "\n",
    "    print(f\"--- Accuracy Report (Checking {min_len} rows) ---\\n\")\n",
    "\n",
    "    for col in columns_to_check:\n",
    "        # Check if column exists (now robust to spaces)\n",
    "        if col not in df_true.columns or col not in df_extracted.columns:\n",
    "            print(f\"Error: Column '{col}' missing.\")\n",
    "            print(f\"   Available in True File: {df_true.columns.tolist()}\")\n",
    "            print(f\"   Available in Extracted: {df_extracted.columns.tolist()}\")\n",
    "            scores[col] = 0.0\n",
    "            continue\n",
    "\n",
    "        # --- Data Normalization ---\n",
    "        true_series = df_true[col].astype(str).fillna('')\n",
    "        extracted_series = df_extracted[col].astype(str).fillna('')\n",
    "\n",
    "        true_clean = true_series.str.strip().str.replace(r'\\.0$', '', regex=True)\n",
    "        extracted_clean = extracted_series.str.strip().str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "        # --- COMPARISON LOGIC ---\n",
    "        if col == 'Name':\n",
    "            row_scores = []\n",
    "            \n",
    "            for t_val, e_val in zip(true_clean, extracted_clean):\n",
    "                \n",
    "                # --- CHECK 1: STRICT ONE-SPACE TOLERANCE ---\n",
    "                t_nospace = t_val.replace(\" \", \"\")\n",
    "                e_nospace = e_val.replace(\" \", \"\")\n",
    "                \n",
    "                # Perfect match\n",
    "                if t_val == e_val:\n",
    "                    row_scores.append(1.0)\n",
    "                    \n",
    "                # Match if characters are same AND length differs by only 1\n",
    "                elif (t_nospace == e_nospace) and (abs(len(t_val) - len(e_val)) <= 1):\n",
    "                    row_scores.append(1.0) \n",
    "                    \n",
    "                # --- CHECK 2: Fallback (Partial Word Match) ---\n",
    "                else:\n",
    "                    t_words = set(t_val.split())\n",
    "                    e_words = set(e_val.split())\n",
    "                    \n",
    "                    if len(t_words) == 0:\n",
    "                        row_scores.append(1.0 if len(e_words) == 0 else 0.0)\n",
    "                    else:\n",
    "                        common = t_words.intersection(e_words)\n",
    "                        score = len(common) / len(t_words)\n",
    "                        row_scores.append(score)\n",
    "            \n",
    "            accuracy = np.mean(row_scores) * 100\n",
    "            \n",
    "        else:\n",
    "            # === STRICT COMPARISON FOR CODES ===\n",
    "            matches = (true_clean == extracted_clean) \n",
    "            accuracy = (matches.sum() / len(matches)) * 100\n",
    "\n",
    "        scores[col] = accuracy\n",
    "        print(f\"{col} Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "    # 3. Calculate Average\n",
    "    if scores:\n",
    "        average_accuracy = sum(scores.values()) / len(scores)\n",
    "    else:\n",
    "        average_accuracy = 0.0\n",
    "\n",
    "    print(f\"\\n--------------------------------\")\n",
    "    print(f\"AVERAGE ACCURACY: {average_accuracy:.2f}%\")\n",
    "    print(f\"--------------------------------\")\n",
    "\n",
    "    return average_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fbbc85a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import easyocr\n",
    "\n",
    "# Initialize the reader for Arabic and English\n",
    "# The model weights will download automatically on the first run\n",
    "#reader = easyocr.Reader(['ar', 'en'], gpu=True) # Set gpu=False if you don't have one\n",
    "\n",
    "# Perform OCR on an image\n",
    "#results = reader.readtext('path_to_your_image.jpg')\n",
    "\n",
    "# Print the recognized text\n",
    "#for (bbox, text, prob) in results:\n",
    "    #print(f\"Text: {text} (Confidence: {prob:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a117bf62",
   "metadata": {},
   "source": [
    "# **Main Pipeline** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40718274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 149 training images...\n",
      "Training Complete. Validation Accuracy: 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "C:\\Users\\ahmed\\AppData\\Roaming\\Python\\Python312\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Complete. Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>Name_Correct</th>\n",
       "      <th>Code</th>\n",
       "      <th>Code_Correct</th>\n",
       "      <th>Daf3</th>\n",
       "      <th>Daf3_Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID1</td>\n",
       "      <td>مصطفى محمود احمد عويس</td>\n",
       "      <td>True</td>\n",
       "      <td>1200277</td>\n",
       "      <td>True</td>\n",
       "      <td>14712020100041</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID2</td>\n",
       "      <td>شاميه علاء محمد سيد احمد</td>\n",
       "      <td>True</td>\n",
       "      <td>1220175</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID3</td>\n",
       "      <td>اسمهان ابراهيم يوسف البيطار</td>\n",
       "      <td>True</td>\n",
       "      <td>1220165</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101214</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID4</td>\n",
       "      <td>حلمي علي ريان</td>\n",
       "      <td>False</td>\n",
       "      <td>1220145</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101495</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID5</td>\n",
       "      <td>حسين محمد ماهر بهاءالدين</td>\n",
       "      <td>False</td>\n",
       "      <td>1220237</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101358</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ID6</td>\n",
       "      <td>محمد منير عبدالحميد كمال</td>\n",
       "      <td>True</td>\n",
       "      <td>4230174</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101524</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ID7</td>\n",
       "      <td>يوسف محمد حمدى محمل عثمان</td>\n",
       "      <td>False</td>\n",
       "      <td>1220301</td>\n",
       "      <td>True</td>\n",
       "      <td>14712522101392</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ID8</td>\n",
       "      <td>معاذ امام احمد امام احمد</td>\n",
       "      <td>True</td>\n",
       "      <td>1220205</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101329</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ID9</td>\n",
       "      <td>نغم طارق مجمد احمد قاسم</td>\n",
       "      <td>False</td>\n",
       "      <td>1220149</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101620</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ID10</td>\n",
       "      <td>يوسف عمرو سيد كمال محمود محمد</td>\n",
       "      <td>True</td>\n",
       "      <td>1220319</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101322</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ID11</td>\n",
       "      <td>يوسف محمل حمزه محمد عبدالتواب</td>\n",
       "      <td>False</td>\n",
       "      <td>1220092</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022100089</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ID12</td>\n",
       "      <td>عمر محمد محمود صفوت احمد سعد الدين</td>\n",
       "      <td>True</td>\n",
       "      <td>1220188</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022100080</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ID13</td>\n",
       "      <td>عبد الرحمن على السيد محما السيد الحديدى</td>\n",
       "      <td>False</td>\n",
       "      <td>1220062</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022100036</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ID14</td>\n",
       "      <td>محمد تامر عبدالعزيز سالم</td>\n",
       "      <td>True</td>\n",
       "      <td>4230189</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101553</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ID15</td>\n",
       "      <td>فادى دامى نبيل داود</td>\n",
       "      <td>False</td>\n",
       "      <td>4230160</td>\n",
       "      <td>True</td>\n",
       "      <td>1471202210078</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ID16</td>\n",
       "      <td>احمد مدحت عبدالعزيز على عوض</td>\n",
       "      <td>True</td>\n",
       "      <td>4230142</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101079</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ID17</td>\n",
       "      <td>مروان عمرو عبدالمجبد فزاد احمد نكرى</td>\n",
       "      <td>False</td>\n",
       "      <td>1220279</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101373</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ID18</td>\n",
       "      <td>عبدالله محمد جمال الدين احمد مصطفى</td>\n",
       "      <td>True</td>\n",
       "      <td>1220256</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101354</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ID19</td>\n",
       "      <td>رغد وليد محمد نبيه فرج حسن</td>\n",
       "      <td>True</td>\n",
       "      <td>1220123</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101537</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ID20</td>\n",
       "      <td>كريم مدمد نجم الدين حمدي عفيفي</td>\n",
       "      <td>False</td>\n",
       "      <td>1220137</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101624</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ID21</td>\n",
       "      <td>عمرو ايهاب مختار فرحات</td>\n",
       "      <td>True</td>\n",
       "      <td>4230159</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101610</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ID22</td>\n",
       "      <td>سارة محمد مصطفى جوده زهير</td>\n",
       "      <td>True</td>\n",
       "      <td>1220125</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101262</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ID23</td>\n",
       "      <td>يوسف جلال محمد نور الدين جلال</td>\n",
       "      <td>True</td>\n",
       "      <td>1200309</td>\n",
       "      <td>True</td>\n",
       "      <td>14712020100046</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ID24</td>\n",
       "      <td>محمد تامر عبدالعزيز سالم</td>\n",
       "      <td>True</td>\n",
       "      <td>4230189</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101553</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ID25</td>\n",
       "      <td>ادهم احمد محمود ممدوح شبانة</td>\n",
       "      <td>True</td>\n",
       "      <td>1230157</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101281</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ID26</td>\n",
       "      <td>عمر ابراهيم احمد ابرا اميم السروى</td>\n",
       "      <td>False</td>\n",
       "      <td>1190533</td>\n",
       "      <td>True</td>\n",
       "      <td>14712019101774</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ID27</td>\n",
       "      <td>اية احمد محمد خشبه</td>\n",
       "      <td>True</td>\n",
       "      <td>1230165</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101223</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ID28</td>\n",
       "      <td>احمد هشام سيل سالم</td>\n",
       "      <td>False</td>\n",
       "      <td>1220003</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022100623</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ID29</td>\n",
       "      <td>حنين محمد اسماعيل محمد حماده</td>\n",
       "      <td>True</td>\n",
       "      <td>1220121</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101552</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ID30</td>\n",
       "      <td>امير سليم سليمان سليمان موسى</td>\n",
       "      <td>True</td>\n",
       "      <td>1210096</td>\n",
       "      <td>True</td>\n",
       "      <td>14712021100205</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>ID31</td>\n",
       "      <td>مدمد عبدالر حيم مالم عبدالهادي</td>\n",
       "      <td>False</td>\n",
       "      <td>1230315</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101217</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>ID32</td>\n",
       "      <td>حسن حسام حسن حامد عبل الفتاح</td>\n",
       "      <td>False</td>\n",
       "      <td>1210216</td>\n",
       "      <td>True</td>\n",
       "      <td>14712021101550</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ID33</td>\n",
       "      <td>زياد ايهاب محمد ممدوح نافع</td>\n",
       "      <td>True</td>\n",
       "      <td>1210227</td>\n",
       "      <td>True</td>\n",
       "      <td>14712021101455</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ID34</td>\n",
       "      <td>اية احمد محمد خشبه</td>\n",
       "      <td>True</td>\n",
       "      <td>1230165</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101223</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ID35</td>\n",
       "      <td>سلمى احمد عبدالرحيم محمد</td>\n",
       "      <td>True</td>\n",
       "      <td>1210235</td>\n",
       "      <td>True</td>\n",
       "      <td>14712021101553</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ID36</td>\n",
       "      <td>ابراهيم محمود ابراهيم عبد المعطى</td>\n",
       "      <td>False</td>\n",
       "      <td>1180568</td>\n",
       "      <td>True</td>\n",
       "      <td>14712018102167</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>ID37</td>\n",
       "      <td>جنى ايمن وفائى محمل عيسى</td>\n",
       "      <td>False</td>\n",
       "      <td>1210349</td>\n",
       "      <td>True</td>\n",
       "      <td>14712021101568</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ID38</td>\n",
       "      <td>سلمى محمد ابرا هيم فتحى ابوريده</td>\n",
       "      <td>False</td>\n",
       "      <td>1230196</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101286</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>ID39</td>\n",
       "      <td>مروان عمرو عبدالمجيد فؤاد احمد شكرى</td>\n",
       "      <td>True</td>\n",
       "      <td>1220279</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101373</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ID40</td>\n",
       "      <td>حسن عمرو مصطفي محمد يوسف</td>\n",
       "      <td>True</td>\n",
       "      <td>1230030</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101060</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>ID41</td>\n",
       "      <td>احمل سامح صلاح مصيلحى</td>\n",
       "      <td>False</td>\n",
       "      <td>4230138</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101505</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>ID42</td>\n",
       "      <td>محمد احمد فهيم عبد الفتاح</td>\n",
       "      <td>False</td>\n",
       "      <td>1220273</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101338</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>ID43</td>\n",
       "      <td>أحمد محمد سيد صابر محمد</td>\n",
       "      <td>True</td>\n",
       "      <td>1230144</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023100148</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>ID44</td>\n",
       "      <td>احمد محمد حسين الكومى</td>\n",
       "      <td>True</td>\n",
       "      <td>1220221</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101628</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>ID45</td>\n",
       "      <td>لينه بهيج محروس بهيج</td>\n",
       "      <td>True</td>\n",
       "      <td>1210284</td>\n",
       "      <td>True</td>\n",
       "      <td>14712021101365</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>ID46</td>\n",
       "      <td>جمانة عمرو مصطفى عبا الصالح عرابي</td>\n",
       "      <td>False</td>\n",
       "      <td>1220229</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101345</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>ID47</td>\n",
       "      <td>مارلى رفعت فاروق عبد السيد</td>\n",
       "      <td>True</td>\n",
       "      <td>1230236</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101120</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>ID48</td>\n",
       "      <td>جمانه تيمور محمد البكرى احمد محمد</td>\n",
       "      <td>True</td>\n",
       "      <td>1220006</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022100861</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>ID49</td>\n",
       "      <td>عبدالله سمير عبد المو جود عسكر</td>\n",
       "      <td>False</td>\n",
       "      <td>1230204</td>\n",
       "      <td>True</td>\n",
       "      <td>14712023101193</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>ID50</td>\n",
       "      <td>حمزة احمد محمد منير الجوهري</td>\n",
       "      <td>True</td>\n",
       "      <td>1220169</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101244</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>ID51</td>\n",
       "      <td>لوجينا شوقي أحمد شحاته</td>\n",
       "      <td>True</td>\n",
       "      <td>1220138</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101562</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ID52</td>\n",
       "      <td>احمد وائل محمد جويد نحيله</td>\n",
       "      <td>True</td>\n",
       "      <td>1220162</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101210</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>ID53</td>\n",
       "      <td>محمد هشام ابرا هيم حسنين</td>\n",
       "      <td>False</td>\n",
       "      <td>1220278</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022101414</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>ID54</td>\n",
       "      <td>يوسف عصام عبدا المنعم احمل منسي</td>\n",
       "      <td>False</td>\n",
       "      <td>1220090</td>\n",
       "      <td>True</td>\n",
       "      <td>14712022100101</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Student ID                                     Name  Name_Correct     Code  \\\n",
       "0         ID1                    مصطفى محمود احمد عويس          True  1200277   \n",
       "1         ID2                 شاميه علاء محمد سيد احمد          True  1220175   \n",
       "2         ID3              اسمهان ابراهيم يوسف البيطار          True  1220165   \n",
       "3         ID4                            حلمي علي ريان         False  1220145   \n",
       "4         ID5                 حسين محمد ماهر بهاءالدين         False  1220237   \n",
       "5         ID6                 محمد منير عبدالحميد كمال          True  4230174   \n",
       "6         ID7                يوسف محمد حمدى محمل عثمان         False  1220301   \n",
       "7         ID8                 معاذ امام احمد امام احمد          True  1220205   \n",
       "8         ID9                  نغم طارق مجمد احمد قاسم         False  1220149   \n",
       "9        ID10            يوسف عمرو سيد كمال محمود محمد          True  1220319   \n",
       "10       ID11            يوسف محمل حمزه محمد عبدالتواب         False  1220092   \n",
       "11       ID12       عمر محمد محمود صفوت احمد سعد الدين          True  1220188   \n",
       "12       ID13  عبد الرحمن على السيد محما السيد الحديدى         False  1220062   \n",
       "13       ID14                 محمد تامر عبدالعزيز سالم          True  4230189   \n",
       "14       ID15                      فادى دامى نبيل داود         False  4230160   \n",
       "15       ID16              احمد مدحت عبدالعزيز على عوض          True  4230142   \n",
       "16       ID17      مروان عمرو عبدالمجبد فزاد احمد نكرى         False  1220279   \n",
       "17       ID18       عبدالله محمد جمال الدين احمد مصطفى          True  1220256   \n",
       "18       ID19               رغد وليد محمد نبيه فرج حسن          True  1220123   \n",
       "19       ID20           كريم مدمد نجم الدين حمدي عفيفي         False  1220137   \n",
       "20       ID21                   عمرو ايهاب مختار فرحات          True  4230159   \n",
       "21       ID22                سارة محمد مصطفى جوده زهير          True  1220125   \n",
       "22       ID23            يوسف جلال محمد نور الدين جلال          True  1200309   \n",
       "23       ID24                 محمد تامر عبدالعزيز سالم          True  4230189   \n",
       "24       ID25              ادهم احمد محمود ممدوح شبانة          True  1230157   \n",
       "25       ID26        عمر ابراهيم احمد ابرا اميم السروى         False  1190533   \n",
       "26       ID27                       اية احمد محمد خشبه          True  1230165   \n",
       "27       ID28                       احمد هشام سيل سالم         False  1220003   \n",
       "28       ID29             حنين محمد اسماعيل محمد حماده          True  1220121   \n",
       "29       ID30             امير سليم سليمان سليمان موسى          True  1210096   \n",
       "30       ID31           مدمد عبدالر حيم مالم عبدالهادي         False  1230315   \n",
       "31       ID32             حسن حسام حسن حامد عبل الفتاح         False  1210216   \n",
       "32       ID33               زياد ايهاب محمد ممدوح نافع          True  1210227   \n",
       "33       ID34                       اية احمد محمد خشبه          True  1230165   \n",
       "34       ID35                 سلمى احمد عبدالرحيم محمد          True  1210235   \n",
       "35       ID36         ابراهيم محمود ابراهيم عبد المعطى         False  1180568   \n",
       "36       ID37                 جنى ايمن وفائى محمل عيسى         False  1210349   \n",
       "37       ID38          سلمى محمد ابرا هيم فتحى ابوريده         False  1230196   \n",
       "38       ID39      مروان عمرو عبدالمجيد فؤاد احمد شكرى          True  1220279   \n",
       "39       ID40                 حسن عمرو مصطفي محمد يوسف          True  1230030   \n",
       "40       ID41                    احمل سامح صلاح مصيلحى         False  4230138   \n",
       "41       ID42                محمد احمد فهيم عبد الفتاح         False  1220273   \n",
       "42       ID43                  أحمد محمد سيد صابر محمد          True  1230144   \n",
       "43       ID44                    احمد محمد حسين الكومى          True  1220221   \n",
       "44       ID45                     لينه بهيج محروس بهيج          True  1210284   \n",
       "45       ID46        جمانة عمرو مصطفى عبا الصالح عرابي         False  1220229   \n",
       "46       ID47               مارلى رفعت فاروق عبد السيد          True  1230236   \n",
       "47       ID48        جمانه تيمور محمد البكرى احمد محمد          True  1220006   \n",
       "48       ID49           عبدالله سمير عبد المو جود عسكر         False  1230204   \n",
       "49       ID50              حمزة احمد محمد منير الجوهري          True  1220169   \n",
       "50       ID51                   لوجينا شوقي أحمد شحاته          True  1220138   \n",
       "51       ID52                احمد وائل محمد جويد نحيله          True  1220162   \n",
       "52       ID53                 محمد هشام ابرا هيم حسنين         False  1220278   \n",
       "53       ID54          يوسف عصام عبدا المنعم احمل منسي         False  1220090   \n",
       "\n",
       "    Code_Correct            Daf3  Daf3_Correct  \n",
       "0           True  14712020100041          True  \n",
       "1           True     14712022101         False  \n",
       "2           True  14712022101214          True  \n",
       "3           True  14712022101495          True  \n",
       "4           True  14712022101358          True  \n",
       "5           True  14712022101524          True  \n",
       "6           True  14712522101392         False  \n",
       "7           True  14712022101329          True  \n",
       "8           True  14712022101620          True  \n",
       "9           True  14712022101322          True  \n",
       "10          True  14712022100089          True  \n",
       "11          True  14712022100080          True  \n",
       "12          True  14712022100036          True  \n",
       "13          True  14712022101553          True  \n",
       "14          True   1471202210078         False  \n",
       "15          True  14712022101079          True  \n",
       "16          True  14712022101373          True  \n",
       "17          True  14712022101354          True  \n",
       "18          True  14712022101537          True  \n",
       "19          True  14712022101624          True  \n",
       "20          True  14712022101610          True  \n",
       "21          True  14712022101262          True  \n",
       "22          True  14712020100046          True  \n",
       "23          True  14712022101553          True  \n",
       "24          True  14712023101281          True  \n",
       "25          True  14712019101774         False  \n",
       "26          True  14712023101223          True  \n",
       "27          True  14712022100623          True  \n",
       "28          True  14712022101552          True  \n",
       "29          True  14712021100205          True  \n",
       "30          True  14712023101217          True  \n",
       "31          True  14712021101550          True  \n",
       "32          True  14712021101455          True  \n",
       "33          True  14712023101223          True  \n",
       "34          True  14712021101553          True  \n",
       "35          True  14712018102167          True  \n",
       "36          True  14712021101568          True  \n",
       "37          True  14712023101286          True  \n",
       "38          True  14712022101373          True  \n",
       "39          True  14712023101060          True  \n",
       "40          True  14712022101505          True  \n",
       "41          True  14712022101338          True  \n",
       "42          True  14712023100148          True  \n",
       "43          True  14712022101628          True  \n",
       "44          True  14712021101365          True  \n",
       "45          True  14712022101345          True  \n",
       "46          True  14712023101120          True  \n",
       "47          True  14712022100861          True  \n",
       "48          True  14712023101193          True  \n",
       "49          True  14712022101244          True  \n",
       "50          True  14712022101562          True  \n",
       "51          True  14712022101210          True  \n",
       "52          True  14712022101414          True  \n",
       "53          True  14712022100101          True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file saved to: Extracted_Results.xlsx\n",
      "--- Accuracy Report (Checking 54 rows) ---\n",
      "\n",
      "Code Accuracy: 100.00%\n",
      "Daf3 Accuracy: 92.59%\n",
      "Name Accuracy: 91.60%\n",
      "\n",
      "--------------------------------\n",
      "AVERAGE ACCURACY: 94.73%\n",
      "--------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from IPython.display import display, Image as IPyImage, HTML\n",
    "\n",
    "def show_image_cv(img, title=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(4, 4))\n",
    "    if len(img.shape) == 2:\n",
    "        plt.imshow(img, cmap='gray')\n",
    "    else:\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def main_pipeline():\n",
    "    base_dir = os.getcwd()\n",
    "    path_to_dataset = os.path.join(base_dir, 'Raw_IDs')\n",
    "    refrence_image_path = os.path.join(base_dir, 'Raw_IDs', 'ID14.jpg')\n",
    "\n",
    "    # Ensure the classifier is trained\n",
    "    SVMclassifier = train_SVM_robust()\n",
    "\n",
    "    data_for_excel = []\n",
    "\n",
    "    # Safety check for directory\n",
    "    if not os.path.exists(path_to_dataset):\n",
    "        print(f\"Directory not found: {path_to_dataset}\")\n",
    "        return\n",
    "\n",
    "    for i in os.listdir(path_to_dataset):\n",
    "        if not i.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff')):\n",
    "            continue\n",
    "        \n",
    "        img_path = os.path.join(path_to_dataset, i)\n",
    "\n",
    "        # --- Processing ---\n",
    "        raw_img = cv2.imread(img_path)\n",
    "        clean_img, is_impulsive = is_impulsive_noise(raw_img)\n",
    "        aligned_img = align_images_sift(clean_img, refrence_image_path)\n",
    "        clean_img2, is_random = is_random_noise(aligned_img)\n",
    "        enhanced_img = enhance_contrast_clahe(clean_img2)\n",
    "        name_img, digit_imgs, daf3_digits = extract_name_and_digits(enhanced_img)\n",
    "        student_id = os.path.splitext(i)[0]\n",
    "\n",
    "        # Save images\n",
    "        save_student_name(student_id, name_img)\n",
    "        save_split_digits(student_id, digit_imgs)\n",
    "        save_split_digits(f\"{student_id}_daf3\", daf3_digits, output_folder=\"extracted_daf3_digits\")\n",
    "\n",
    "        # Predict Code\n",
    "        digit_preds = []\n",
    "        for digit_img in digit_imgs:\n",
    "            feat = extract_hog_features(digit_img)\n",
    "            pred = SVMclassifier.predict([feat])[0]\n",
    "            digit_preds.append(str(pred))\n",
    "        code_str = ''.join(digit_preds)\n",
    "\n",
    "        # Predict Daf3\n",
    "        daf3_preds = []\n",
    "        for d_img in daf3_digits:\n",
    "            feat = extract_hog_features(d_img)\n",
    "            pred = SVMclassifier.predict([feat])[0]\n",
    "            daf3_preds.append(str(pred))\n",
    "        daf3_str = ''.join(daf3_preds)\n",
    "\n",
    "        # Extract Name\n",
    "        name_text = extractname(f'./extracted_names/{student_id}_name.jpg')\n",
    "\n",
    "        # Add to list\n",
    "        data_for_excel.append({\n",
    "            \"Student ID\": student_id,   \n",
    "            \"Name\": name_text,\n",
    "            \"Code\": code_str,\n",
    "            \"Daf3\": daf3_str,\n",
    "        })\n",
    "\n",
    "    # --- OUTPUT SECTION ---\n",
    "    if data_for_excel:\n",
    "        df = pd.DataFrame(data_for_excel)\n",
    "        # Sort by Student ID number if needed\n",
    "        df = df.sort_values(by=\"Student ID\", key=lambda x: x.str.extract(r'(\\d+)').iloc[:, 0].astype(int))\n",
    "\n",
    "        # 1. DISPLAY TABLE IN JUPYTER (with Student ID) + 3 correctness columns\n",
    "        print(\"Processing Complete. Results:\")\n",
    "        true_results_path = 'True_Results.xlsx'\n",
    "\n",
    "        df_display = df[['Student ID', 'Name', 'Code', 'Daf3']].copy()\n",
    "        if os.path.exists(true_results_path):\n",
    "            try:\n",
    "                true_df = pd.read_excel(true_results_path)\n",
    "                true_df.columns = true_df.columns.str.strip()\n",
    "\n",
    "                def _key(c: str) -> str:\n",
    "                    return re.sub(r\"[^a-z0-9]\", \"\", str(c).strip().lower())\n",
    "\n",
    "                colmap = {_key(c): c for c in true_df.columns}\n",
    "                sid_col = colmap.get('studentid') or colmap.get('student_id') or colmap.get('id')\n",
    "                if sid_col is None:\n",
    "                    raise KeyError(f\"No student-id column found. Columns: {list(true_df.columns)}\")\n",
    "                true_df = true_df.rename(columns={sid_col: 'Student ID'})\n",
    "\n",
    "                name_col = colmap.get('name')\n",
    "                code_col = colmap.get('code')\n",
    "                daf3_col = colmap.get('daf3')\n",
    "                if name_col and name_col != 'Name':\n",
    "                    true_df = true_df.rename(columns={name_col: 'Name'})\n",
    "                if code_col and code_col != 'Code':\n",
    "                    true_df = true_df.rename(columns={code_col: 'Code'})\n",
    "                if daf3_col and daf3_col != 'Daf3':\n",
    "                    true_df = true_df.rename(columns={daf3_col: 'Daf3'})\n",
    "\n",
    "                left = df_display.copy()\n",
    "                right = true_df.copy()\n",
    "                left['_sid_key'] = left['Student ID'].astype(str).str.extract(r'(\\d+)')[0]\n",
    "                right['_sid_key'] = right['Student ID'].astype(str).str.extract(r'(\\d+)')[0]\n",
    "                merged = left.merge(right, on='_sid_key', how='left', suffixes=('', '_True'))\n",
    "\n",
    "                def _norm_series(s: pd.Series) -> pd.Series:\n",
    "                    return s.astype(str).fillna('').str.strip().str.replace(r'\\.0$', '', regex=True)\n",
    "\n",
    "                merged['Name_Correct'] = _norm_series(merged['Name']) == _norm_series(merged.get('Name_True', ''))\n",
    "                merged['Code_Correct'] = _norm_series(merged['Code']) == _norm_series(merged.get('Code_True', ''))\n",
    "                merged['Daf3_Correct'] = _norm_series(merged['Daf3']) == _norm_series(merged.get('Daf3_True', ''))\n",
    "\n",
    "                df_display = merged[[\n",
    "                    'Student ID',\n",
    "                    'Name', 'Name_Correct',\n",
    "                    'Code', 'Code_Correct',\n",
    "                    'Daf3', 'Daf3_Correct',\n",
    "                ]]\n",
    "            except Exception as e:\n",
    "                print(f\"Could not add correctness columns: {e}\")\n",
    "\n",
    "        display(df_display)\n",
    "\n",
    "        # 2. SAVE TO EXCEL\n",
    "        output_file = \"Extracted_Results.xlsx\"\n",
    "        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "            df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "\n",
    "            # Auto-resize columns\n",
    "            worksheet = writer.sheets['Sheet1']\n",
    "            for column in df:\n",
    "                column_length = max(df[column].astype(str).map(len).max(), len(column))\n",
    "                col_idx = df.columns.get_loc(column)\n",
    "                col_letter = chr(65 + col_idx)\n",
    "                worksheet.column_dimensions[col_letter].width = column_length + 2\n",
    "\n",
    "# ... (Excel saving code) ...\n",
    "\n",
    "        print(f\"Excel file saved to: {output_file}\")\n",
    "        \n",
    "        # <--- CHANGE 3: The call happens here, after the file exists\n",
    "        true_results_path = 'True_Results.xlsx' \n",
    "        \n",
    "        if os.path.exists(true_results_path):\n",
    "            calculate_pipeline_accuracy(true_results_path, output_file)\n",
    "        else:\n",
    "            print(f\"Skipping accuracy check: '{true_results_path}' not found.\")\n",
    "\n",
    "# Run it\n",
    "main_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2ebfad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Quick sanity check for PaddleOCR runtime\n",
    "# import os\n",
    "\n",
    "# os.environ.setdefault(\"DISABLE_MODEL_SOURCE_CHECK\", \"True\")\n",
    "\n",
    "# import paddle\n",
    "# from paddleocr import PaddleOCR\n",
    "\n",
    "# print('paddle:', paddle.__version__)\n",
    "# print('cuda compiled:', paddle.device.is_compiled_with_cuda())\n",
    "\n",
    "# # PaddleOCR v3.x: no `use_gpu`; CPU is used automatically with CPU paddle builds\n",
    "# ocr = PaddleOCR(lang='ar', use_textline_orientation=True)\n",
    "# print('PaddleOCR ready')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e833afca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Debug: inspect one name crop + PaddleOCR detected tokens\n",
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def _poly_center(poly):\n",
    "#     try:\n",
    "#         xs = [float(p[0]) for p in poly]\n",
    "#         ys = [float(p[1]) for p in poly]\n",
    "#         return (sum(xs) / len(xs), sum(ys) / len(ys))\n",
    "#     except Exception:\n",
    "#         return (0.0, 0.0)\n",
    "\n",
    "# name_dir = 'extracted_names'\n",
    "# name_files = sorted([f for f in os.listdir(name_dir) if f.lower().endswith(('.jpg','.png','.jpeg'))])\n",
    "# print('name images:', len(name_files))\n",
    "\n",
    "# if not name_files:\n",
    "#     raise RuntimeError(f'No images found in {name_dir!r}')\n",
    "\n",
    "# sample_file = name_files[0]\n",
    "# sample_path = os.path.join(name_dir, sample_file)\n",
    "# img0 = cv2.imread(sample_path)\n",
    "# print('sample:', sample_file, 'shape:', None if img0 is None else img0.shape, 'mean:', None if img0 is None else float(np.mean(img0)))\n",
    "\n",
    "# show_image_cv(img0, title=f'Name crop: {sample_file}')\n",
    "\n",
    "# # Run OCR the same way as extractname()\n",
    "# img = cv2.copyMakeBorder(img0, 10, 10, 60, 60, cv2.BORDER_CONSTANT, value=(255, 255, 255))\n",
    "# raw = ocr.ocr(img)\n",
    "\n",
    "# if isinstance(raw, list) and raw and isinstance(raw[0], dict):\n",
    "#     page = raw[0]\n",
    "#     rec_texts = page.get('rec_texts') or []\n",
    "#     rec_polys = page.get('rec_polys') or []\n",
    "\n",
    "#     print('\\nrec_texts:', rec_texts)\n",
    "\n",
    "#     if isinstance(rec_texts, list) and isinstance(rec_polys, list) and len(rec_texts) == len(rec_polys):\n",
    "#         items = []\n",
    "#         for t, poly in zip(rec_texts, rec_polys):\n",
    "#             cx, cy = _poly_center(poly)\n",
    "#             items.append((cx, cy, t))\n",
    "\n",
    "#         print('\\nDetected (sorted RTL by x):')\n",
    "#         for cx, cy, t in sorted(items, key=lambda x: x[0], reverse=True):\n",
    "#             print(f'  x={cx:7.1f} y={cy:6.1f}  {t}')\n",
    "\n",
    "# print('\\nextractname():', extractname(sample_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6886914b",
   "metadata": {},
   "source": [
    "## Qwen2.5-VL pretrained OCR (comparison only)\n",
    "- This section does **not** change your pipeline or existing OCR code.\n",
    "- It runs a pretrained Qwen2.5-VL OCR model on the already-saved name crops in `extracted_names/` and writes a separate Excel file for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "074f5479",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Qwen comparison dependencies (SAFE CHECK-ONLY cell)\n",
    "# # This cell does NOT install/upgrade anything (no downloads, no env overwrites).\n",
    "# # If something is missing, it prints the exact one-time commands to run in a Terminal.\n",
    "\n",
    "# import os, sys, importlib\n",
    "# from importlib.util import find_spec\n",
    "\n",
    "# os.environ.setdefault('KMP_DUPLICATE_LIB_OK', 'TRUE')\n",
    "\n",
    "# import torch\n",
    "# print('torch:', torch.__version__, 'cuda_available:', torch.cuda.is_available())\n",
    "# if not torch.cuda.is_available():\n",
    "#     raise RuntimeError('CUDA is not available in this kernel. Fix the conda CUDA torch stack and restart the kernel.')\n",
    "# print('GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# # Versions pinned to avoid pip/conda conflicts (and to keep torch CUDA intact).\n",
    "# REQUIRED = {\n",
    "#     'huggingface_hub': '0.34.4',\n",
    "#     'transformers': '4.57.3',\n",
    "#     'accelerate': '0.30.1',\n",
    "# }\n",
    "\n",
    "# def _get_version(mod_name: str) -> str | None:\n",
    "#     try:\n",
    "#         m = importlib.import_module(mod_name)\n",
    "#         return getattr(m, '__version__', None)\n",
    "#     except Exception:\n",
    "#         return None\n",
    "\n",
    "# problems = []\n",
    "\n",
    "# # Required core deps (version-pinned)\n",
    "# for pkg, want in REQUIRED.items():\n",
    "#     got = _get_version(pkg)\n",
    "#     if got is None:\n",
    "#         problems.append(f'{pkg} is missing')\n",
    "#     elif got != want:\n",
    "#         problems.append(f'{pkg} is {got} (expected {want})')\n",
    "#     else:\n",
    "#         print(f'{pkg}: {got}')\n",
    "\n",
    "# # Non-version-pinned deps\n",
    "# for pkg in ('sentencepiece', 'einops'):\n",
    "#     if find_spec(pkg) is None:\n",
    "#         problems.append(f'{pkg} is missing')\n",
    "#     else:\n",
    "#         v = _get_version(pkg)\n",
    "#         print(f'{pkg}: {v or \"OK\"}')\n",
    "\n",
    "# # bitsandbytes: DO NOT import here (it registers torch ops at import-time).\n",
    "# if find_spec('bitsandbytes') is None:\n",
    "#     problems.append('bitsandbytes is missing')\n",
    "# else:\n",
    "#     print('bitsandbytes: installed (will be imported in the model cell)')\n",
    "\n",
    "# if problems:\n",
    "#     print('\\nDependency problems detected:')\n",
    "#     for p in problems:\n",
    "#         print(' -', p)\n",
    "#     print('\\nFix once in a Terminal (NOT in a notebook cell):')\n",
    "#     print('  1) Make sure pip did not install torch/numpy:')\n",
    "#     print('     python -m pip uninstall -y torch torchvision torchaudio numpy')\n",
    "#     print('  2) Restore CUDA torch via conda (if needed):')\n",
    "#     print('     conda install -y -n imageproc pytorch=2.2.2 torchvision=0.17.2 torchaudio=2.2.2 pytorch-cuda=12.1 -c pytorch -c nvidia')\n",
    "#     print('  3) Install the pinned Qwen deps WITHOUT deps (so pip cannot overwrite torch):')\n",
    "#     print('     python -m pip install --no-deps huggingface-hub==0.34.4 transformers==4.57.3 accelerate==0.30.1 bitsandbytes==0.47.0 sentencepiece einops')\n",
    "#     print('  4) Restart the notebook kernel, then re-run this cell.')\n",
    "#     raise RuntimeError('Qwen deps are not in the expected safe state. See printed fix commands.')\n",
    "\n",
    "# print('\\nQwen deps look safe. Next: run the model-load cell (it may download model weights to the HF cache).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ff21031",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Qwen2_5_VLForConditionalGeneration, AutoProcessor\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Transformers may call torch.compiler.is_compiling() (Torch 2.3+).\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Torch 2.2 provides torch.compiler but can miss is_compiling, so we shim it.\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen2_5_VLForConditionalGeneration, AutoProcessor\n",
    "import torch\n",
    "\n",
    "# Transformers may call torch.compiler.is_compiling() (Torch 2.3+).\n",
    "# Torch 2.2 provides torch.compiler but can miss is_compiling, so we shim it.\n",
    "try:\n",
    "    import torch.compiler as _torch_compiler\n",
    "    if not hasattr(_torch_compiler, \"is_compiling\"):\n",
    "        if hasattr(torch, \"_dynamo\") and hasattr(torch._dynamo, \"is_compiling\"):\n",
    "            _torch_compiler.is_compiling = torch._dynamo.is_compiling\n",
    "        else:\n",
    "            _torch_compiler.is_compiling = lambda: False\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "from PIL import Image\n",
    "from typing import List\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, Image as IPyImage, HTML, clear_output\n",
    "\n",
    "os.environ.setdefault('KMP_DUPLICATE_LIB_OK', 'TRUE')\n",
    "\n",
    "# -----------------------\n",
    "# Notebook progress knobs\n",
    "# -----------------------\n",
    "SHOW_LIVE_PROGRESS = True          # prints status and updates live\n",
    "SHOW_IMAGE_PREVIEW = True          # show the current crop image inline\n",
    "SHOW_EVERY_N = 1                   # show every N images (1 = all)\n",
    "MAX_PREVIEW = 30                   # cap previews to avoid flooding the notebook\n",
    "SHOW_TABLE_EVERY_N = 10            # update a small results table every N images\n",
    "\n",
    "\n",
    "def _maybe_display_image(path: str, width: int = 500):\n",
    "    if not SHOW_IMAGE_PREVIEW:\n",
    "        return\n",
    "    if not os.path.exists(path):\n",
    "        return\n",
    "    try:\n",
    "        display(HTML(f\"<div style='margin:6px 0; font-weight:600'>Preview: {os.path.basename(path)}</div>\"))\n",
    "        display(IPyImage(filename=path, width=width))\n",
    "    except Exception:\n",
    "        # If display fails for any reason, just skip preview.\n",
    "        pass\n",
    "\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError('CUDA is not available. Fix torch CUDA first, then restart kernel and re-run.')\n",
    "print('Using GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# bitsandbytes can already be imported in the kernel (e.g., from a previous run).\n",
    "# That's okay; we warn instead of stopping.\n",
    "if 'bitsandbytes' in sys.modules:\n",
    "    print('Note: bitsandbytes is already imported in this kernel; continuing.')\n",
    "\n",
    "\n",
    "def process_vision_info(messages: List[dict]):\n",
    "    image_inputs = []\n",
    "    video_inputs = []\n",
    "    for message in messages:\n",
    "        if isinstance(message[\"content\"], list):\n",
    "            for item in message[\"content\"]:\n",
    "                if item[\"type\"] == \"image\":\n",
    "                    image = item[\"image\"]\n",
    "                    if isinstance(image, str):\n",
    "                        image = Image.open(image).convert(\"RGB\")\n",
    "                    elif isinstance(image, Image.Image):\n",
    "                        pass\n",
    "                    else:\n",
    "                        raise ValueError(f\"Unsupported image type: {type(image)}\")\n",
    "                    image_inputs.append(image)\n",
    "                elif item[\"type\"] == \"video\":\n",
    "                    video_inputs.append(item[\"video\"])\n",
    "    return image_inputs if image_inputs else None, video_inputs if video_inputs else None\n",
    "\n",
    "\n",
    "def _clean_arabic_name(text: str) -> str:\n",
    "    if not text:\n",
    "        return ''\n",
    "    # Keep Arabic letters + spaces only (removes digits/codes/latin/punctuation).\n",
    "    cleaned = re.sub(r\"[^\\u0621-\\u064A\\s]\", \" \", str(text))\n",
    "    cleaned = re.sub(r\"\\s+\", \" \", cleaned).strip()\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def _normalize_name_value(v) -> str:\n",
    "    s = '' if v is None else str(v)\n",
    "    s = s.strip()\n",
    "    s = s.replace('\\u200f', '').replace('\\u200e', '')\n",
    "    s = s.replace('\\xa0', ' ')\n",
    "    s = s.replace('\\t', ' ')\n",
    "    s = s.replace('\\r', ' ').replace('\\n', ' ')\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    if s.endswith('.0'):\n",
    "        s = s[:-2]\n",
    "    return s.strip()\n",
    "\n",
    "\n",
    "def _exact_name_match(true_name: str, pred_name: str) -> bool:\n",
    "    return _normalize_name_value(true_name) == _normalize_name_value(pred_name)\n",
    "\n",
    "\n",
    "def _is_name_correct(true_name: str, pred_name: str) -> bool:\n",
    "    # Your existing tolerance rule (used for accuracy scoring): exact match OR one-space tolerance\n",
    "    t = _normalize_name_value(true_name)\n",
    "    p = _normalize_name_value(pred_name)\n",
    "    if t == p:\n",
    "        return True\n",
    "    t_nospace = t.replace(' ', '')\n",
    "    p_nospace = p.replace(' ', '')\n",
    "    return (t_nospace == p_nospace) and (abs(len(t) - len(p)) <= 1)\n",
    "\n",
    "\n",
    "def _name_score(true_name: str, pred_name: str) -> float:\n",
    "    t = _normalize_name_value(true_name)\n",
    "    p = _normalize_name_value(pred_name)\n",
    "    # Perfect match\n",
    "    if t == p:\n",
    "        return 1.0\n",
    "    # One-space tolerance\n",
    "    if _is_name_correct(t, p):\n",
    "        return 1.0\n",
    "    # Partial word match\n",
    "    t_words = set(t.split())\n",
    "    p_words = set(p.split())\n",
    "    if len(t_words) == 0:\n",
    "        return 1.0 if len(p_words) == 0 else 0.0\n",
    "    common = t_words.intersection(p_words)\n",
    "    return len(common) / len(t_words)\n",
    "\n",
    "\n",
    "def _name_accuracy(true_names: List[str], pred_names: List[str]) -> float:\n",
    "    scores = [_name_score(t, p) for t, p in zip(true_names, pred_names)]\n",
    "    return float(np.mean(scores) * 100) if scores else 0.0\n",
    "\n",
    "\n",
    "# 4-bit model (requires bitsandbytes).\n",
    "model_name = \"sherif1313/Arabic-handwritten-OCR-4bit-Qwen2.5-VL-3B-v2\"\n",
    "model = Qwen2_5_VLForConditionalGeneration.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    dtype=torch.float16,\n",
    "    trust_remote_code=True,\n",
    "    low_cpu_mem_usage=True,\n",
    ")\n",
    "\n",
    "try:\n",
    "    device_map = getattr(model, 'hf_device_map', None)\n",
    "    if isinstance(device_map, dict):\n",
    "        print('hf_device_map:', device_map)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
    "\n",
    "\n",
    "def extract_name_from_image(image_path: str) -> str:\n",
    "    # Ask for the student's name only (no codes / numbers).\n",
    "    prompt = (\n",
    "        \"استخرج اسم الطالب فقط من الصورة. \"\n",
    "        \"اكتب الاسم العربي فقط بدون أرقام أو رموز أو كلمات إضافية.\"\n",
    "    )\n",
    "    try:\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\"type\": \"image\", \"image\": image_path},\n",
    "                    {\"type\": \"text\", \"text\": prompt},\n",
    "                ],\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        text = processor.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "        image_inputs, _video_inputs = process_vision_info(messages)\n",
    "        inputs = processor(\n",
    "            text=[text],\n",
    "            images=image_inputs,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        ).to(model.device)\n",
    "\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            pad_token_id=processor.tokenizer.eos_token_id,\n",
    "            eos_token_id=processor.tokenizer.eos_token_id,\n",
    "        )\n",
    "\n",
    "        input_len = inputs.input_ids.shape[1]\n",
    "        output_text = processor.batch_decode(\n",
    "            generated_ids[:, input_len:],\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=True,\n",
    "        )[0]\n",
    "        return _clean_arabic_name(output_text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {os.path.basename(image_path)}: {e}\")\n",
    "        return ''\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# Run Qwen on name crops ONLY and evaluate ONLY name accuracy.\n",
    "###############################################################################\n",
    "\n",
    "NAMES_DIR = 'extracted_names'\n",
    "BASELINE_XLSX = 'Extracted_Results.xlsx'\n",
    "TRUE_XLSX = 'True_Results.xlsx'\n",
    "QWEN_XLSX = 'Qwen_Results.xlsx'\n",
    "\n",
    "if not os.path.isdir(NAMES_DIR):\n",
    "    raise RuntimeError(f\"{NAMES_DIR!r} folder not found. Run the main pipeline first to generate name crops.\")\n",
    "if not os.path.exists(BASELINE_XLSX):\n",
    "    raise RuntimeError(f\"{BASELINE_XLSX!r} not found. Run the main pipeline first (it generates this file).\")\n",
    "\n",
    "df_base = pd.read_excel(BASELINE_XLSX)\n",
    "df_base.columns = df_base.columns.str.strip()\n",
    "if 'Student ID' not in df_base.columns:\n",
    "    raise RuntimeError(f\"{BASELINE_XLSX!r} is missing 'Student ID' column.\")\n",
    "\n",
    "# Run Qwen for each student's name crop\n",
    "qwen_rows = []\n",
    "preview_count = 0\n",
    "n_total = int(df_base.shape[0])\n",
    "\n",
    "for i, sid in enumerate(df_base['Student ID'].astype(str).tolist(), start=1):\n",
    "    img_path = os.path.join(NAMES_DIR, f\"{sid}_name.jpg\")\n",
    "    if not os.path.exists(img_path):\n",
    "        alt = os.path.join(NAMES_DIR, f\"{sid}.jpg\")\n",
    "        img_path = alt if os.path.exists(alt) else img_path\n",
    "\n",
    "    do_show = (SHOW_LIVE_PROGRESS and (i % int(SHOW_EVERY_N) == 0))\n",
    "\n",
    "    if do_show:\n",
    "        clear_output(wait=True)\n",
    "        print(f\"Qwen processing: {i}/{n_total} | Student ID: {sid}\")\n",
    "        print(f\"Image: {img_path}\")\n",
    "\n",
    "        if preview_count < int(MAX_PREVIEW):\n",
    "            _maybe_display_image(img_path)\n",
    "            preview_count += 1\n",
    "\n",
    "    qwen_name = extract_name_from_image(img_path) if os.path.exists(img_path) else ''\n",
    "    qwen_rows.append({'Student ID': sid, 'Name': qwen_name})\n",
    "\n",
    "    if do_show:\n",
    "        print(\"\\nQwen output (cleaned):\")\n",
    "        print(qwen_name)\n",
    "\n",
    "        if SHOW_TABLE_EVERY_N and (i % int(SHOW_TABLE_EVERY_N) == 0):\n",
    "            df_live = pd.DataFrame(qwen_rows)\n",
    "            display(df_live.tail(min(10, len(df_live))))\n",
    "\n",
    "# Final save\n",
    "clear_output(wait=False)\n",
    "df_qwen = pd.DataFrame(qwen_rows)\n",
    "df_qwen.to_excel(QWEN_XLSX, index=False)\n",
    "print(f\"Saved Qwen name-only results to: {QWEN_XLSX}\")\n",
    "display(df_qwen.head(10))\n",
    "\n",
    "# Evaluate name accuracy and show comparison table\n",
    "if not os.path.exists(TRUE_XLSX):\n",
    "    print(f\"Note: {TRUE_XLSX!r} not found, so accuracy/table are skipped.\")\n",
    "    display(df_qwen)\n",
    "else:\n",
    "    df_true = pd.read_excel(TRUE_XLSX)\n",
    "    df_true.columns = df_true.columns.str.strip()\n",
    "\n",
    "    # Build comparison table aligned by Student ID when possible\n",
    "    if 'Student ID' in df_true.columns and 'Name' in df_true.columns and 'Name' in df_base.columns:\n",
    "        df_true_k = df_true[['Student ID', 'Name']].copy()\n",
    "        df_true_k['Student ID'] = df_true_k['Student ID'].astype(str)\n",
    "        df_base_k = df_base[['Student ID', 'Name']].copy()\n",
    "        df_base_k['Student ID'] = df_base_k['Student ID'].astype(str)\n",
    "        df_qwen_k = df_qwen[['Student ID', 'Name']].copy()\n",
    "        df_qwen_k['Student ID'] = df_qwen_k['Student ID'].astype(str)\n",
    "\n",
    "        table = df_true_k.merge(df_base_k, on='Student ID', how='inner', suffixes=('_Actual', '_MyCode'))\n",
    "        table = table.merge(df_qwen_k, on='Student ID', how='inner')\n",
    "        table = table.rename(columns={'Name': 'Qwen Output'})\n",
    "        table = table.rename(columns={'Name_Actual': 'Actual Name', 'Name_MyCode': 'My Code Output'})\n",
    "\n",
    "        # Right/Wrong uses the tolerance rule (same as accuracy scoring).\n",
    "        table['Qwen Right/Wrong'] = [\n",
    "            'Right' if _is_name_correct(a, q) else 'Wrong'\n",
    "            for a, q in zip(table['Actual Name'], table['Qwen Output'])\n",
    "        ]\n",
    "\n",
    "        # Requested boolean columns: True only when extracted == true (exact match after normalization).\n",
    "        table['My Code == True'] = [\n",
    "            _exact_name_match(a, m) for a, m in zip(table['Actual Name'], table['My Code Output'])\n",
    "        ]\n",
    "        table['Qwen == True'] = [\n",
    "            _exact_name_match(a, q) for a, q in zip(table['Actual Name'], table['Qwen Output'])\n",
    "        ]\n",
    "        table['Both == True'] = table['My Code == True'] & table['Qwen == True']\n",
    "\n",
    "        baseline_name_acc = _name_accuracy(table['Actual Name'].tolist(), table['My Code Output'].tolist())\n",
    "        qwen_name_acc = _name_accuracy(table['Actual Name'].tolist(), table['Qwen Output'].tolist())\n",
    "        print(f\"Baseline Name Accuracy: {baseline_name_acc:.2f}%\")\n",
    "        print(f\"Qwen Name Accuracy:     {qwen_name_acc:.2f}%\")\n",
    "        print(f\"Name Delta (baseline - Qwen): {baseline_name_acc - qwen_name_acc:+.2f} points\")\n",
    "\n",
    "        display(table[['Student ID', 'Actual Name', 'My Code Output', 'Qwen Output', 'Qwen Right/Wrong', 'My Code == True', 'Qwen == True', 'Both == True']])\n",
    "    else:\n",
    "        # Fallback: align by row order (if Student ID isn't available in the true file).\n",
    "        min_len = min(len(df_true), len(df_base), len(df_qwen))\n",
    "        actual = df_true.get('Name', pd.Series([''] * min_len)).iloc[:min_len].tolist()\n",
    "        mycode = df_base.get('Name', pd.Series([''] * min_len)).iloc[:min_len].tolist()\n",
    "        qwen = df_qwen.get('Name', pd.Series([''] * min_len)).iloc[:min_len].tolist()\n",
    "\n",
    "        baseline_name_acc = _name_accuracy(actual, mycode)\n",
    "        qwen_name_acc = _name_accuracy(actual, qwen)\n",
    "        print(f\"Baseline Name Accuracy: {baseline_name_acc:.2f}%\")\n",
    "        print(f\"Qwen Name Accuracy:     {qwen_name_acc:.2f}%\")\n",
    "        print(f\"Name Delta (baseline - Qwen): {baseline_name_acc - qwen_name_acc:+.2f} points\")\n",
    "\n",
    "        table = pd.DataFrame({\n",
    "            'Row': list(range(1, min_len + 1)),\n",
    "            'Actual Name': actual,\n",
    "            'My Code Output': mycode,\n",
    "            'Qwen Output': qwen,\n",
    "        })\n",
    "        table['Qwen Right/Wrong'] = [\n",
    "            'Right' if _is_name_correct(a, q) else 'Wrong'\n",
    "            for a, q in zip(table['Actual Name'], table['Qwen Output'])\n",
    "        ]\n",
    "        table['My Code == True'] = [\n",
    "            _exact_name_match(a, m) for a, m in zip(table['Actual Name'], table['My Code Output'])\n",
    "        ]\n",
    "        table['Qwen == True'] = [\n",
    "            _exact_name_match(a, q) for a, q in zip(table['Actual Name'], table['Qwen Output'])\n",
    "        ]\n",
    "        table['Both == True'] = table['My Code == True'] & table['Qwen == True']\n",
    "\n",
    "        display(table[['Row', 'Actual Name', 'My Code Output', 'Qwen Output', 'Qwen Right/Wrong', 'My Code == True', 'Qwen == True', 'Both == True']])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imageproc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
