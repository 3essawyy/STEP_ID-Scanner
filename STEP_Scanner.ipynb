{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff14649",
   "metadata": {},
   "source": [
    "# **Synthetic English Number Dataset Generation Scripts**\n",
    "\n",
    "## **Script 1: Basic Augmentation (Optimal)**\n",
    "The first commented block generates a digit dataset (0-9) with basic augmentations:\n",
    "- **Random rotation** (-10 to 10 degrees)\n",
    "- **Gaussian blur** (simulates out-of-focus camera)\n",
    "- **Noise addition** (simulates sensor grain)\n",
    "- **Erosion/Dilation** (simulates ink bleeding or thin print)\n",
    "\n",
    "Uses a single font (Arial) and creates 200 samples per digit.\n",
    "\n",
    "## **Script 2: Advanced Defects (Non-Optimal)**\n",
    "The second commented block generates a more heavily augmented dataset with:\n",
    "- **Multiple fonts** (Arial, Sitka) for style variation\n",
    "- **Perspective warping** (simulates camera angle distortion)\n",
    "- **Character breaking** (scratches and missing chunks)\n",
    "- **Shadow simulation** (uneven lighting gradients)\n",
    "- **Salt & pepper noise** (random black/white pixels)\n",
    "- **Gaussian blur**\n",
    "\n",
    "Creates 400 samples per digit but may over-augment, making digits harder to recognize (hence \"non-optimal\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "2cb20fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# # --- CONFIGURATION ---\n",
    "# OUTPUT_DIR = \"dataset\"\n",
    "# SAMPLES_PER_DIGIT = 200 # How many images per number to generate\n",
    "# IMG_SIZE = (64, 64)      # Canvas size (larger than target to allow rotation/cropping)\n",
    "# FONT_PATH = \"arial.ttf\"  # <--- COPY A FONT FILE HERE!\n",
    "# FONT_SIZE = 45\n",
    "\n",
    "# # Create folders 0-9\n",
    "# if not os.path.exists(OUTPUT_DIR):\n",
    "#     os.makedirs(OUTPUT_DIR)\n",
    "# for i in range(10):\n",
    "#     os.makedirs(os.path.join(OUTPUT_DIR, str(i)), exist_ok=True)\n",
    "\n",
    "# def apply_augmentations(img_pil):\n",
    "#     \"\"\"\n",
    "#     Takes a clean PIL image and ruins it to look like a scanned ID.\n",
    "#     \"\"\"\n",
    "#     # Convert to NumPy for OpenCV processing\n",
    "#     img = np.array(img_pil) \n",
    "    \n",
    "#     # 1. Random Rotation (-10 to 10 degrees)\n",
    "#     angle = random.uniform(-10, 10)\n",
    "#     h, w = img.shape\n",
    "#     M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)\n",
    "#     img = cv2.warpAffine(img, M, (w, h), borderValue=0) # Black border\n",
    "\n",
    "#     # 2. Gaussian Blur (Simulate out-of-focus camera)\n",
    "#     if random.random() > 0.5:\n",
    "#         k = random.choice([3, 5])\n",
    "#         img = cv2.GaussianBlur(img, (k, k), 0)\n",
    "\n",
    "#     # 3. Noise (Simulate sensor grain)\n",
    "#     noise = np.random.randint(0, 50, (h, w), dtype='uint8')\n",
    "#     # Add noise only to non-black areas mostly, or just add it overall\n",
    "#     img = cv2.add(img, noise)\n",
    "\n",
    "#     # 4. Erosion/Dilation (Simulate ink bleeding or thin print)\n",
    "#     if random.random() > 0.5:\n",
    "#         kernel = np.ones((2,2), np.uint8)\n",
    "#         if random.choice([True, False]):\n",
    "#             img = cv2.erode(img, kernel, iterations=1)\n",
    "#         else:\n",
    "#             img = cv2.dilate(img, kernel, iterations=1)\n",
    "\n",
    "#     return img\n",
    "\n",
    "# def generate_dataset():\n",
    "#     print(f\"Generating {SAMPLES_PER_DIGIT} images per digit...\")\n",
    "    \n",
    "#     try:\n",
    "#         font = ImageFont.truetype(FONT_PATH, FONT_SIZE)\n",
    "#     except IOError:\n",
    "#         print(\"ERROR: Font file not found! Please put 'arial.ttf' in this folder.\")\n",
    "#         return\n",
    "\n",
    "#     for digit in range(10):\n",
    "#         print(f\"Processing digit: {digit}\")\n",
    "#         for i in range(SAMPLES_PER_DIGIT):\n",
    "#             # 1. Create a blank black image\n",
    "#             img_pil = Image.new('L', IMG_SIZE, color=0)\n",
    "#             draw = ImageDraw.Draw(img_pil)\n",
    "            \n",
    "#             # 2. Draw the digit in white centered(ish)\n",
    "#             # We add random offset so the number isn't always perfectly in the middle\n",
    "#             text = str(digit)\n",
    "#             # Get text bounding box to center it\n",
    "#             bbox = draw.textbbox((0, 0), text, font=font)\n",
    "#             text_w = bbox[2] - bbox[0]\n",
    "#             text_h = bbox[3] - bbox[1]\n",
    "            \n",
    "#             x = (IMG_SIZE[0] - text_w) / 2 + random.randint(-5, 5)\n",
    "#             y = (IMG_SIZE[1] - text_h) / 2 + random.randint(-5, 5)\n",
    "            \n",
    "#             draw.text((x, y), text, font=font, fill=255)\n",
    "            \n",
    "#             # 3. Apply the \"Reality\" effects\n",
    "#             final_img = apply_augmentations(img_pil)\n",
    "            \n",
    "#             # 4. Save\n",
    "#             save_path = os.path.join(OUTPUT_DIR, str(digit), f\"{digit}_{i}.png\")\n",
    "#             cv2.imwrite(save_path, final_img)\n",
    "\n",
    "#     print(\"Done! You now have a dataset.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     generate_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "1ec27cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "# import random\n",
    "# from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# # --- CONFIGURATION ---\n",
    "# OUTPUT_DIR = \"dataset_mixed\"\n",
    "# SAMPLES_PER_DIGIT = 400  # Total images per digit\n",
    "# IMG_SIZE = (64, 64)\n",
    "\n",
    "# # List your fonts here. Ensure these files are in the folder!\n",
    "# FONTS = [\"arial.ttf\", \"Sitka.ttc\"] \n",
    "# FONT_SIZE = 45\n",
    "\n",
    "# # Create output folders\n",
    "# if not os.path.exists(OUTPUT_DIR):\n",
    "#     os.makedirs(OUTPUT_DIR)\n",
    "# for i in range(10):\n",
    "#     os.makedirs(os.path.join(OUTPUT_DIR, str(i)), exist_ok=True)\n",
    "\n",
    "# def add_shadow(img):\n",
    "#     \"\"\"Simulates uneven lighting.\"\"\"\n",
    "#     h, w = img.shape\n",
    "#     top_left = random.uniform(0.5, 1.0)\n",
    "#     bot_right = random.uniform(0.5, 1.0)\n",
    "#     X, Y = np.meshgrid(np.arange(w), np.arange(h))\n",
    "#     mask = top_left + (bot_right - top_left) * (X / w)\n",
    "#     img = img.astype('float32') * mask\n",
    "#     return img.astype('uint8')\n",
    "\n",
    "# def break_character(img):\n",
    "#     \"\"\"Simulates scratches and missing chunks.\"\"\"\n",
    "#     h, w = img.shape\n",
    "    \n",
    "#     # Random scratch line\n",
    "#     if random.random() > 0.5:\n",
    "#         num_scratches = random.randint(1, 3)\n",
    "#         for _ in range(num_scratches):\n",
    "#             x1, y1 = random.randint(0, w), random.randint(0, h)\n",
    "#             x2, y2 = random.randint(0, w), random.randint(0, h)\n",
    "#             cv2.line(img, (x1, y1), (x2, y2), 0, random.randint(1, 3))\n",
    "\n",
    "#     # Random noise chunks missing\n",
    "#     if random.random() > 0.5:\n",
    "#         noise = np.zeros((h, w), dtype='uint8')\n",
    "#         cv2.randn(noise, 0, 255)\n",
    "#         _, holes = cv2.threshold(noise, 200, 255, cv2.THRESH_BINARY)\n",
    "#         img = cv2.subtract(img, holes)\n",
    "        \n",
    "#     return img\n",
    "\n",
    "# def apply_defects(img_pil):\n",
    "#     img = np.array(img_pil)\n",
    "    \n",
    "#     # 1. Perspective Warp\n",
    "#     h, w = img.shape\n",
    "#     src_points = np.float32([[0,0], [w,0], [0,h], [w,h]])\n",
    "#     dst_points = np.float32([\n",
    "#         [random.randint(0, 5), random.randint(0, 5)],\n",
    "#         [w - random.randint(0, 5), random.randint(0, 5)],\n",
    "#         [random.randint(0, 5), h - random.randint(0, 5)],\n",
    "#         [w - random.randint(0, 5), h - random.randint(0, 5)]\n",
    "#     ])\n",
    "#     M = cv2.getPerspectiveTransform(src_points, dst_points)\n",
    "#     img = cv2.warpPerspective(img, M, (w, h))\n",
    "\n",
    "#     # 2. Break Character\n",
    "#     img = break_character(img)\n",
    "\n",
    "#     # 3. Blur\n",
    "#     if random.random() > 0.3:\n",
    "#         k = random.choice([3, 5])\n",
    "#         img = cv2.GaussianBlur(img, (k, k), 0)\n",
    "\n",
    "#     # 4. Shadow\n",
    "#     if random.random() > 0.4:\n",
    "#         img = add_shadow(img)\n",
    "\n",
    "#     # 5. Salt & Pepper Noise\n",
    "#     noise_prob = 0.02\n",
    "#     thres = 1 - noise_prob\n",
    "#     rdn = np.random.random(img.shape)\n",
    "#     img[rdn < noise_prob] = 0\n",
    "#     img[rdn > thres] = 255\n",
    "\n",
    "#     return img\n",
    "\n",
    "# def generate_dataset():\n",
    "#     print(f\"Generating {SAMPLES_PER_DIGIT} images per digit using fonts: {FONTS}\")\n",
    "    \n",
    "#     # Verify fonts exist\n",
    "#     loaded_fonts = []\n",
    "#     for f_name in FONTS:\n",
    "#         try:\n",
    "#             loaded_fonts.append(ImageFont.truetype(f_name, FONT_SIZE))\n",
    "#         except IOError:\n",
    "#             print(f\"WARNING: Could not load {f_name}. Skipping.\")\n",
    "    \n",
    "#     if not loaded_fonts:\n",
    "#         print(\"ERROR: No fonts found! Please copy .ttf files to this folder.\")\n",
    "#         return\n",
    "\n",
    "#     for digit in range(10):\n",
    "#         print(f\"Processing digit: {digit}\")\n",
    "#         for i in range(SAMPLES_PER_DIGIT):\n",
    "#             # 1. Randomly choose a font\n",
    "#             font = random.choice(loaded_fonts)\n",
    "            \n",
    "#             # 2. Draw Text\n",
    "#             img_pil = Image.new('L', IMG_SIZE, color=0)\n",
    "#             draw = ImageDraw.Draw(img_pil)\n",
    "            \n",
    "#             text = str(digit)\n",
    "#             bbox = draw.textbbox((0, 0), text, font=font)\n",
    "#             text_w, text_h = bbox[2] - bbox[0], bbox[3] - bbox[1]\n",
    "#             x = (IMG_SIZE[0] - text_w) / 2 + random.randint(-8, 8)\n",
    "#             y = (IMG_SIZE[1] - text_h) / 2 + random.randint(-8, 8)\n",
    "            \n",
    "#             draw.text((x, y), text, font=font, fill=255)\n",
    "            \n",
    "#             # 3. Apply Defects\n",
    "#             final_img = apply_defects(img_pil)\n",
    "            \n",
    "#             # 4. Save\n",
    "#             save_path = os.path.join(OUTPUT_DIR, str(digit), f\"{digit}_{i}.png\")\n",
    "#             cv2.imwrite(save_path, final_img)\n",
    "\n",
    "#     print(f\"Done! Created {SAMPLES_PER_DIGIT * 10} images in '{OUTPUT_DIR}'\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     generate_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc4e2bc",
   "metadata": {},
   "source": [
    "## **Imports**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c180f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier  # MLP is an NN\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import argparse\n",
    "#import imutils  # If you are unable to install this library, ask the TA; we only need this in extract_hsv_histogram.\n",
    "import cv2\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import pytesseract\n",
    "from sklearn.svm import LinearSVC\n",
    "# Depending on library versions on your system, one of the following imports \n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.cross_validation import train_test_split\n",
    "import pytesseract\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from arabic_reshaper import reshape\n",
    "from bidi.algorithm import get_display\n",
    "import pandas as pd\n",
    "from openpyxl.utils import get_column_letter  # Add this line\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe' # (Windows Example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "id": "c32ccb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = \"./Synthetic_numbers_dataset_mixed\"\n",
    "\n",
    "target_img_size = (32, 32) # fix image size because classification algorithms THAT WE WILL USE HERE expect that\n",
    "# We are going to fix the random seed to make our experiments reproducible \n",
    "# since some algorithms use pseudorandom generators\n",
    "random_seed = 42  \n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f17014",
   "metadata": {},
   "source": [
    "## **SVM English Number Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "3a33c621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_hog_features(img):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    You won't implement anything in this function. You just need to understand it \n",
    "    and understand its parameters (i.e win_size, cell_size, ... etc)\n",
    "    \"\"\"\n",
    "    img = cv2.resize(img, target_img_size)\n",
    "    win_size = (32, 32)\n",
    "    cell_size = (4, 4)\n",
    "    block_size_in_cells = (2, 2)\n",
    "    \n",
    "    block_size = (block_size_in_cells[1] * cell_size[1], block_size_in_cells[0] * cell_size[0])\n",
    "    block_stride = (cell_size[1], cell_size[0])\n",
    "    nbins = 9  # Number of orientation bins\n",
    "    hog = cv2.HOGDescriptor(win_size, block_size, block_stride, cell_size, nbins)\n",
    "    h = hog.compute(img)\n",
    "    h = h.flatten()\n",
    "    return h.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "1e45a34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(feature_set='hog'):\n",
    "    features = []\n",
    "    labels = []\n",
    "    img_filenames = os.listdir(path_to_dataset)\n",
    "    total_processed = 0\n",
    "    total_images = 0\n",
    "    for folder in img_filenames:    \n",
    "        total_images += len(img_filenames) * len(os.listdir(os.path.join(path_to_dataset, folder)))   # 10 folders * 400 images each = 4000\n",
    "    total_images = total_images // 10\n",
    "    for i, fn in enumerate(img_filenames):\n",
    "        NumberInnerPath = os.path.join(path_to_dataset, str(i))\n",
    "        NumberInnerPath = os.listdir(NumberInnerPath)\n",
    "        for idx, img_filename in enumerate(NumberInnerPath):\n",
    "            if img_filename.split('.')[-1] != 'png':\n",
    "                continue\n",
    "\n",
    "            label = str(i)\n",
    "            labels.append(label)\n",
    "\n",
    "            # Build the full file path\n",
    "            full_path = os.path.join(path_to_dataset, str(i), img_filename)\n",
    "            img = cv2.imread(full_path)\n",
    "            features.append(extract_hog_features(img))\n",
    "            \n",
    "            total_processed += 1\n",
    "            \n",
    "            # show an update every 50 images\n",
    "            if total_processed > 0 and total_processed % 50 == 0:\n",
    "                print(\"[INFO] processed {}/{} images\".format(total_processed, total_images))\n",
    "        \n",
    "    return features, labels        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "5092b9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_SVM():\n",
    "    SVMclassifier=svm.LinearSVC(random_state=random_seed)\n",
    "    features, labels = load_dataset()\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size=0.4, random_state=random_seed)\n",
    "    SVMclassifier.fit(train_features,train_labels)\n",
    "    accuracy=SVMclassifier.score(test_features,test_labels)\n",
    "    print(\"SVM Accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "cf82cf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] processed 50/4000 images\n",
      "[INFO] processed 100/4000 images\n",
      "[INFO] processed 150/4000 images\n",
      "[INFO] processed 200/4000 images\n",
      "[INFO] processed 250/4000 images\n",
      "[INFO] processed 300/4000 images\n",
      "[INFO] processed 350/4000 images\n",
      "[INFO] processed 400/4000 images\n",
      "[INFO] processed 450/4000 images\n",
      "[INFO] processed 500/4000 images\n",
      "[INFO] processed 550/4000 images\n",
      "[INFO] processed 600/4000 images\n",
      "[INFO] processed 650/4000 images\n",
      "[INFO] processed 700/4000 images\n",
      "[INFO] processed 750/4000 images\n",
      "[INFO] processed 800/4000 images\n",
      "[INFO] processed 850/4000 images\n",
      "[INFO] processed 900/4000 images\n",
      "[INFO] processed 950/4000 images\n",
      "[INFO] processed 1000/4000 images\n",
      "[INFO] processed 1050/4000 images\n",
      "[INFO] processed 1100/4000 images\n",
      "[INFO] processed 1150/4000 images\n",
      "[INFO] processed 1200/4000 images\n",
      "[INFO] processed 1250/4000 images\n",
      "[INFO] processed 1300/4000 images\n",
      "[INFO] processed 1350/4000 images\n",
      "[INFO] processed 1400/4000 images\n",
      "[INFO] processed 1450/4000 images\n",
      "[INFO] processed 1500/4000 images\n",
      "[INFO] processed 1550/4000 images\n",
      "[INFO] processed 1600/4000 images\n",
      "[INFO] processed 1650/4000 images\n",
      "[INFO] processed 1700/4000 images\n",
      "[INFO] processed 1750/4000 images\n",
      "[INFO] processed 1800/4000 images\n",
      "[INFO] processed 1850/4000 images\n",
      "[INFO] processed 1900/4000 images\n",
      "[INFO] processed 1950/4000 images\n",
      "[INFO] processed 2000/4000 images\n",
      "[INFO] processed 2050/4000 images\n",
      "[INFO] processed 2100/4000 images\n",
      "[INFO] processed 2150/4000 images\n",
      "[INFO] processed 2200/4000 images\n",
      "[INFO] processed 2250/4000 images\n",
      "[INFO] processed 2300/4000 images\n",
      "[INFO] processed 2350/4000 images\n",
      "[INFO] processed 2400/4000 images\n",
      "[INFO] processed 2450/4000 images\n",
      "[INFO] processed 2500/4000 images\n",
      "[INFO] processed 2550/4000 images\n",
      "[INFO] processed 2600/4000 images\n",
      "[INFO] processed 2650/4000 images\n",
      "[INFO] processed 2700/4000 images\n",
      "[INFO] processed 2750/4000 images\n",
      "[INFO] processed 2800/4000 images\n",
      "[INFO] processed 2850/4000 images\n",
      "[INFO] processed 2900/4000 images\n",
      "[INFO] processed 2950/4000 images\n",
      "[INFO] processed 3000/4000 images\n",
      "[INFO] processed 3050/4000 images\n",
      "[INFO] processed 3100/4000 images\n",
      "[INFO] processed 3150/4000 images\n",
      "[INFO] processed 3200/4000 images\n",
      "[INFO] processed 3250/4000 images\n",
      "[INFO] processed 3300/4000 images\n",
      "[INFO] processed 3350/4000 images\n",
      "[INFO] processed 3400/4000 images\n",
      "[INFO] processed 3450/4000 images\n",
      "[INFO] processed 3500/4000 images\n",
      "[INFO] processed 3550/4000 images\n",
      "[INFO] processed 3600/4000 images\n",
      "[INFO] processed 3650/4000 images\n",
      "[INFO] processed 3700/4000 images\n",
      "[INFO] processed 3750/4000 images\n",
      "[INFO] processed 3800/4000 images\n",
      "[INFO] processed 3850/4000 images\n",
      "[INFO] processed 3900/4000 images\n",
      "[INFO] processed 3950/4000 images\n",
      "[INFO] processed 4000/4000 images\n",
      "SVM Accuracy:  0.875625\n"
     ]
    }
   ],
   "source": [
    "train_SVM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "065fbfe0",
   "metadata": {},
   "source": [
    "# **Tesseract Arabic OCR**\n",
    "\n",
    "## **Current Situation**\n",
    "\n",
    "The project uses Tesseract OCR to extract Arabic names from scanned images. Initially, the extraction pipeline achieved only a **70% success rate**. This meant that about 30% of the images failed to yield any valid Arabic text, even though the images were visually clear and contained readable names.\n",
    "\n",
    "## **Why Was the Success Rate Only 70%?**\n",
    "\n",
    "- **Overprocessing:** The original code applied several preprocessing steps (scaling, thresholding, blurring, etc.) before running OCR. While these steps can help with noisy or low-contrast images, they often **destroy clean, high-contrast text**—especially for Arabic, where fine details matter.\n",
    "- **Order of Operations:** The pipeline tried processed versions first, so if the original image was already optimal, it was never used for OCR.\n",
    "- **PSM/OEM Settings:** The code tried a limited set of Tesseract Page Segmentation Modes (PSM) and OCR Engine Modes (OEM), which may not have been optimal for all images.\n",
    "- **Text Cleaning:** The cleaning function was aggressive, but if Tesseract output was empty or too short, the result was discarded.\n",
    "\n",
    "## **What Was Changed to Achieve 100% Success**\n",
    "\n",
    "1. **Prioritize the Original Image:**  \n",
    "   The new code always tries the original, unprocessed grayscale image first, with several PSM settings. This ensures that clean images are not degraded by unnecessary processing.\n",
    "\n",
    "2. **Expanded Preprocessing (But Only If Needed):**  \n",
    "   Only if the original image fails, the code tries padded and scaled versions, but never applies destructive thresholding or blurring unless absolutely necessary.\n",
    "\n",
    "3. **Multiple PSM and OEM Combinations:**  \n",
    "   For each image variant, the code tries several PSM (6, 7, 3, 13) and both OEM (3, 1) settings, maximizing the chance that Tesseract will interpret the layout correctly.\n",
    "\n",
    "4. **Result Selection:**  \n",
    "   All non-empty results are collected, and the **longest valid extraction** is chosen, which is usually the correct full name.\n",
    "\n",
    "5. **Diagnostics:**  \n",
    "   Additional debug and diagnostic code was used to confirm that the original image, with minimal processing, consistently yields the best results for this dataset.\n",
    "\n",
    "## Reference\n",
    "\n",
    "The old (70%) code is left in the notebook for comparison. The new approach, as described above, achieves **100% extraction success** on the current dataset by respecting the quality of the input images and leveraging Tesseract's flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e532a6b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing images in: test_arabic_names_full...\n",
      "\n",
      "==================================================\n",
      "OCR EXTRACTION RESULTS\n",
      "==================================================\n",
      "Total Images Processed: 50\n",
      "Successful Extractions: 50\n",
      "Failed Extractions:     0\n",
      "Success Rate:           100.00%\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Extracted Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0.png</td>\n",
       "      <td>محمود محمد يوسف السيد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_1.png</td>\n",
       "      <td>خالدحينمصودعزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_10.png</td>\n",
       "      <td>محمود سعيد عليعزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_11.png</td>\n",
       "      <td>عبدالله مصطفى إبراهيم الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_12.png</td>\n",
       "      <td>أحمد خالد عبدالله الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>id_13.png</td>\n",
       "      <td>خالد مود سعيد عامر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>id_14.png</td>\n",
       "      <td>زياد مصطفى حسين سليمان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>id_15.png</td>\n",
       "      <td>مصطفى إبراهيم يوسف الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>id_16.png</td>\n",
       "      <td>حسين خالد حسين عبدالرحمن</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>id_17.png</td>\n",
       "      <td>سعيد يوسف خالد سليمان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>id_18.png</td>\n",
       "      <td>أحمد خالد أحمد سليمان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>id_19.png</td>\n",
       "      <td>سعيد يوسف علي السيه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>id_2.png</td>\n",
       "      <td>علي طارق أحمد المنشاوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>id_20.png</td>\n",
       "      <td>عمر إبراهيم كريم نجيب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>id_21.png</td>\n",
       "      <td>زياد حسن يوسف المصري</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>id_22.png</td>\n",
       "      <td>خالد يوسف طارق نجيب</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>id_23.png</td>\n",
       "      <td>مصطفى خالد حسن عزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>id_24.png</td>\n",
       "      <td>كريم علي أحمد الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>id_25.png</td>\n",
       "      <td>حسن حسين طارق الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>id_26.png</td>\n",
       "      <td>سعيد سعيد زياد عزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>id_27.png</td>\n",
       "      <td>يوسف محمد مصودعزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>id_28.png</td>\n",
       "      <td>يوسفعمر مود عاص</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>id_29.png</td>\n",
       "      <td>طارق حسين زياد المنشاوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>id_3.png</td>\n",
       "      <td>علي إبراهيم خالد عزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>id_30.png</td>\n",
       "      <td>يوسف حبين مصود عاص</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>id_31.png</td>\n",
       "      <td>إبراهيم حسن مصطفى المصري</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>id_32.png</td>\n",
       "      <td>محمد عمر كريمالمتشاوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>id_33.png</td>\n",
       "      <td>محمود مصطفى عبدلله اليد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>id_34.png</td>\n",
       "      <td>أحمد خالد علي الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>id_35.png</td>\n",
       "      <td>كريم علي حسنالمصري</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>id_36.png</td>\n",
       "      <td>كريم حسين يوسف عزرت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>id_37.png</td>\n",
       "      <td>طارق إبراهيم إبراهيم عامر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>id_38.png</td>\n",
       "      <td>سعيد مصطفى زياد عزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>id_39.png</td>\n",
       "      <td>زياد محمود خالد السيد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>id_4.png</td>\n",
       "      <td>محمد إبراهيم طارق السيد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>id_40.png</td>\n",
       "      <td>عليعمرمصدعزت</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>id_41.png</td>\n",
       "      <td>خالد خالد محمد الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>id_42.png</td>\n",
       "      <td>أحمد خالد علي المنشاوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>id_43.png</td>\n",
       "      <td>عمر علي خلد عاص</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>id_44.png</td>\n",
       "      <td>ن عبدالرحمن كريم إبراهيم حسن عبدالر</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>id_45.png</td>\n",
       "      <td>خال د كريم طارقالسيه</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>id_46.png</td>\n",
       "      <td>محمود محمد طرق سليمان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>id_47.png</td>\n",
       "      <td>طارق طارق زياد المنشاوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>id_48.png</td>\n",
       "      <td>محمود أحمد سعيد سليمان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>id_49.png</td>\n",
       "      <td>محمود خالد إبراهيم السيد</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>id_5.png</td>\n",
       "      <td>زياد يوسف محمد المصري</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>id_6.png</td>\n",
       "      <td>طارق عمر يوسفالمصري</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>id_7.png</td>\n",
       "      <td>إيراهيم عمر محمود الشناوي</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>id_8.png</td>\n",
       "      <td>سعيد محمود مصطفى سليمان</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>id_9.png</td>\n",
       "      <td>يوسف أحمد زياد عزت</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Filename                       Extracted Name\n",
       "0    id_0.png                محمود محمد يوسف السيد\n",
       "1    id_1.png                       خالدحينمصودعزت\n",
       "2   id_10.png                    محمود سعيد عليعزت\n",
       "3   id_11.png        عبدالله مصطفى إبراهيم الشناوي\n",
       "4   id_12.png            أحمد خالد عبدالله الشناوي\n",
       "5   id_13.png                   خالد مود سعيد عامر\n",
       "6   id_14.png               زياد مصطفى حسين سليمان\n",
       "7   id_15.png           مصطفى إبراهيم يوسف الشناوي\n",
       "8   id_16.png             حسين خالد حسين عبدالرحمن\n",
       "9   id_17.png                سعيد يوسف خالد سليمان\n",
       "10  id_18.png                أحمد خالد أحمد سليمان\n",
       "11  id_19.png                  سعيد يوسف علي السيه\n",
       "12   id_2.png               علي طارق أحمد المنشاوي\n",
       "13  id_20.png                عمر إبراهيم كريم نجيب\n",
       "14  id_21.png                 زياد حسن يوسف المصري\n",
       "15  id_22.png                  خالد يوسف طارق نجيب\n",
       "16  id_23.png                   مصطفى خالد حسن عزت\n",
       "17  id_24.png                كريم علي أحمد الشناوي\n",
       "18  id_25.png                حسن حسين طارق الشناوي\n",
       "19  id_26.png                   سعيد سعيد زياد عزت\n",
       "20  id_27.png                    يوسف محمد مصودعزت\n",
       "21  id_28.png                      يوسفعمر مود عاص\n",
       "22  id_29.png              طارق حسين زياد المنشاوي\n",
       "23   id_3.png                 علي إبراهيم خالد عزت\n",
       "24  id_30.png                   يوسف حبين مصود عاص\n",
       "25  id_31.png             إبراهيم حسن مصطفى المصري\n",
       "26  id_32.png                محمد عمر كريمالمتشاوي\n",
       "27  id_33.png              محمود مصطفى عبدلله اليد\n",
       "28  id_34.png                أحمد خالد علي الشناوي\n",
       "29  id_35.png                   كريم علي حسنالمصري\n",
       "30  id_36.png                  كريم حسين يوسف عزرت\n",
       "31  id_37.png            طارق إبراهيم إبراهيم عامر\n",
       "32  id_38.png                  سعيد مصطفى زياد عزت\n",
       "33  id_39.png                زياد محمود خالد السيد\n",
       "34   id_4.png              محمد إبراهيم طارق السيد\n",
       "35  id_40.png                         عليعمرمصدعزت\n",
       "36  id_41.png               خالد خالد محمد الشناوي\n",
       "37  id_42.png               أحمد خالد علي المنشاوي\n",
       "38  id_43.png                      عمر علي خلد عاص\n",
       "39  id_44.png  ن عبدالرحمن كريم إبراهيم حسن عبدالر\n",
       "40  id_45.png                 خال د كريم طارقالسيه\n",
       "41  id_46.png                محمود محمد طرق سليمان\n",
       "42  id_47.png              طارق طارق زياد المنشاوي\n",
       "43  id_48.png               محمود أحمد سعيد سليمان\n",
       "44  id_49.png             محمود خالد إبراهيم السيد\n",
       "45   id_5.png                زياد يوسف محمد المصري\n",
       "46   id_6.png                  طارق عمر يوسفالمصري\n",
       "47   id_7.png            إيراهيم عمر محمود الشناوي\n",
       "48   id_8.png              سعيد محمود مصطفى سليمان\n",
       "49   id_9.png                   يوسف أحمد زياد عزت"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def extractname(img_path):\n",
    "    \n",
    "#     # --- HELPER: TEXT CLEANER ---\n",
    "#     def clean_text(raw_text):\n",
    "#         if not raw_text: return \"\"\n",
    "#         # Keep Arabic letters (0621-064A) and spaces\n",
    "#         cleaned = re.sub(r'[^\\u0621-\\u064A\\s]', '', raw_text)\n",
    "#         cleaned = cleaned.replace('\\n', ' ')\n",
    "#         cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "#         return cleaned\n",
    "\n",
    "#     # --- LOAD IMAGE AS GRAYSCALE DIRECTLY ---\n",
    "#     img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "#     if img_gray is None: \n",
    "#         return \"\"\n",
    "\n",
    "#     configs = [\n",
    "#         # --- TIER 1: Simple approaches ---\n",
    "#         {'scale': 1, 'process': 'none', 'psm': 7},\n",
    "#         {'scale': 2, 'process': 'none', 'psm': 6},\n",
    "#         {'scale': 2, 'process': 'none', 'psm': 7},\n",
    "\n",
    "#         # --- TIER 2: With thresholding ---\n",
    "#         {'scale': 2, 'process': 'otsu', 'psm': 7},\n",
    "#         {'scale': 2, 'process': 'otsu', 'psm': 6},\n",
    "#         {'scale': 2, 'process': 'blur_otsu', 'psm': 6},\n",
    "\n",
    "#         # --- TIER 3: Last resort ---\n",
    "#         {'scale': 2, 'process': 'adaptive', 'psm': 6},\n",
    "#         {'scale': 3, 'process': 'otsu', 'psm': 6},\n",
    "#     ]\n",
    "\n",
    "#     for config in configs:\n",
    "#         current = img_gray.copy()\n",
    "            \n",
    "#         # A. Scaling\n",
    "#         if config['scale'] > 1:\n",
    "#             h, w = current.shape\n",
    "#             current = cv2.resize(current, (w * config['scale'], h * config['scale']), interpolation=cv2.INTER_CUBIC)\n",
    "            \n",
    "#         # B. Processing Logic\n",
    "#         process = config['process']\n",
    "        \n",
    "#         if process == 'otsu':\n",
    "#             _, current = cv2.threshold(current, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            \n",
    "#         elif process == 'blur_otsu':\n",
    "#             current = cv2.GaussianBlur(current, (5, 5), 0)\n",
    "#             _, current = cv2.threshold(current, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            \n",
    "#         elif process == 'adaptive':\n",
    "#             current = cv2.adaptiveThreshold(current, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, \n",
    "#                                             cv2.THRESH_BINARY, 11, 2)\n",
    "\n",
    "#         # C. Padding (white border)\n",
    "#         current = cv2.copyMakeBorder(current, 40, 40, 40, 40, cv2.BORDER_CONSTANT, value=255)\n",
    "        \n",
    "#         # D. Execution\n",
    "#         custom_config = f\"--oem 3 --psm {config['psm']}\"\n",
    "#         text = pytesseract.image_to_string(current, lang='ara', config=custom_config)\n",
    "#         final_text = clean_text(text)\n",
    "        \n",
    "#         # E. Validation\n",
    "#         if len(final_text) > 2:\n",
    "#             return final_text\n",
    "\n",
    "#     return \"\"\n",
    "\n",
    "def extractname(img_path):\n",
    "    \n",
    "    # --- HELPER: TEXT CLEANER ---\n",
    "    def clean_text(raw_text):\n",
    "        if not raw_text: return \"\"\n",
    "        # Keep Arabic letters (0621-064A) and spaces\n",
    "        cleaned = re.sub(r'[^\\u0621-\\u064A\\s]', '', raw_text)\n",
    "        cleaned = cleaned.replace('\\n', ' ')\n",
    "        cleaned = re.sub(r'\\s+', ' ', cleaned).strip()\n",
    "        return cleaned\n",
    "\n",
    "    # --- LOAD IMAGE AS GRAYSCALE DIRECTLY ---\n",
    "    img_gray = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img_gray is None: \n",
    "        return \"\"\n",
    "\n",
    "    # Try multiple approaches and collect all results\n",
    "    all_results = []\n",
    "    \n",
    "    # Preprocessing variants\n",
    "    preprocessed_images = {\n",
    "        'original': img_gray,\n",
    "        'padded': cv2.copyMakeBorder(img_gray, 40, 40, 40, 40, cv2.BORDER_CONSTANT, value=255),\n",
    "    }\n",
    "    \n",
    "    # Add scaled version\n",
    "    h, w = img_gray.shape\n",
    "    scaled = cv2.resize(img_gray, (w*2, h*2), interpolation=cv2.INTER_CUBIC)\n",
    "    preprocessed_images['scaled_padded'] = cv2.copyMakeBorder(scaled, 40, 40, 40, 40, cv2.BORDER_CONSTANT, value=255)\n",
    "    \n",
    "    # PSM modes to try\n",
    "    psm_modes = [6, 7, 3, 13]  # 13 = raw line\n",
    "    \n",
    "    for img_name, img in preprocessed_images.items():\n",
    "        for psm in psm_modes:\n",
    "            for oem in [3, 1]:  # Try both LSTM+Legacy and LSTM only\n",
    "                try:\n",
    "                    config = f\"--oem {oem} --psm {psm}\"\n",
    "                    text = pytesseract.image_to_string(img, lang='ara', config=config)\n",
    "                    cleaned = clean_text(text)\n",
    "                    \n",
    "                    if len(cleaned) > 2:\n",
    "                        all_results.append((cleaned, len(cleaned), img_name, psm, oem))\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    # Return the longest valid result\n",
    "    if all_results:\n",
    "        all_results.sort(key=lambda x: x[1], reverse=True)\n",
    "        return all_results[0][0]\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "folder_path = 'test_arabic_names_full'\n",
    "data = []\n",
    "if os.path.exists(folder_path):\n",
    "    print(f\"Processing images in: {folder_path}...\\n\")\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        # Check if the file is an image\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp')):\n",
    "            full_path = os.path.join(folder_path, filename)\n",
    "            extracted_text = extractname(full_path)    \n",
    "            clean_text_result = extracted_text.strip()\n",
    "            data.append({'Filename': filename, 'Extracted Name': clean_text_result})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # ===== SUCCESS RATE CALCULATION =====\n",
    "    total_images = len(df)\n",
    "    successful_extractions = len(df[df['Extracted Name'] != ''])\n",
    "    failed_extractions = total_images - successful_extractions\n",
    "    success_rate = (successful_extractions / total_images) * 100 if total_images > 0 else 0\n",
    "    \n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"OCR EXTRACTION RESULTS\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"Total Images Processed: {total_images}\")\n",
    "    print(f\"Successful Extractions: {successful_extractions}\")\n",
    "    print(f\"Failed Extractions:     {failed_extractions}\")\n",
    "    print(f\"Success Rate:           {success_rate:.2f}%\")\n",
    "    print(f\"{'='*50}\\n\")\n",
    "    \n",
    "    # Show failed images\n",
    "    if failed_extractions > 0:\n",
    "        failed_df = df[df['Extracted Name'] == '']\n",
    "        print(\"Failed to extract text from:\")\n",
    "        for idx, row in failed_df.iterrows():\n",
    "            print(f\"  - {row['Filename']}\")\n",
    "        print()\n",
    "    \n",
    "    display(df.head(50))\n",
    "    \n",
    "else:\n",
    "    print(f\"the folder '{folder_path}' was not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8dbd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Saved to 'arabic_names_final.xlsx' with auto-adjusted columns.\n"
     ]
    }
   ],
   "source": [
    "if 'df' in locals() and not df.empty:\n",
    "    final_df = df.copy()\n",
    "    final_df['ID'] = final_df.apply(lambda x: random.randint(1000000, 9999999), axis=1)\n",
    "        # Rename and Select Columns\n",
    "    final_df.rename(columns={'Extracted Name': 'Name'}, inplace=True)\n",
    "    final_df = final_df[['Name', 'ID']]    \n",
    "    output_filename = 'arabic_names_final.xlsx'\n",
    "    with pd.ExcelWriter(output_filename, engine='openpyxl') as writer:\n",
    "        final_df.to_excel(writer, sheet_name='Names', index=False)\n",
    "        workbook = writer.book\n",
    "        worksheet = writer.sheets['Names']\n",
    "        for i, column in enumerate(final_df.columns):\n",
    "            column_letter = get_column_letter(i + 1) # Get A, B, C...\n",
    "            max_len = final_df[column].astype(str).map(len).max()\n",
    "            max_len = max(max_len, len(column))\n",
    "            worksheet.column_dimensions[column_letter].width = (max_len + 2) * 1.2\n",
    "            \n",
    "    print(f\"Success! Saved to '{output_filename}' with auto-adjusted columns.\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: Please run the OCR extraction code first.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
